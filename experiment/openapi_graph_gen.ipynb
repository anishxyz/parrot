{
 "cells": [
  {
   "cell_type": "code",
   "source": "!pip install pydantic anytree networkx matplotlib inflect openapi-core jsonref",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T05:02:03.249090Z",
     "start_time": "2024-07-09T05:02:01.612832Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydantic in /Users/anishagrawal/Desktop/Development/parrot/venv/lib/python3.11/site-packages (2.8.2)\r\n",
      "Requirement already satisfied: anytree in /Users/anishagrawal/Desktop/Development/parrot/venv/lib/python3.11/site-packages (2.12.1)\r\n",
      "Requirement already satisfied: networkx in /Users/anishagrawal/Desktop/Development/parrot/venv/lib/python3.11/site-packages (3.3)\r\n",
      "Requirement already satisfied: matplotlib in /Users/anishagrawal/Desktop/Development/parrot/venv/lib/python3.11/site-packages (3.9.1)\r\n",
      "Requirement already satisfied: inflect in /Users/anishagrawal/Desktop/Development/parrot/venv/lib/python3.11/site-packages (7.3.1)\r\n",
      "Requirement already satisfied: openapi-core in /Users/anishagrawal/Desktop/Development/parrot/venv/lib/python3.11/site-packages (0.19.2)\r\n",
      "Requirement already satisfied: jsonref in /Users/anishagrawal/Desktop/Development/parrot/venv/lib/python3.11/site-packages (1.1.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/anishagrawal/Desktop/Development/parrot/venv/lib/python3.11/site-packages (from pydantic) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/anishagrawal/Desktop/Development/parrot/venv/lib/python3.11/site-packages (from pydantic) (2.20.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/anishagrawal/Desktop/Development/parrot/venv/lib/python3.11/site-packages (from pydantic) (4.12.2)\r\n",
      "Requirement already satisfied: six in /Users/anishagrawal/Desktop/Development/parrot/venv/lib/python3.11/site-packages (from anytree) (1.16.0)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/anishagrawal/Desktop/Development/parrot/venv/lib/python3.11/site-packages (from matplotlib) (1.2.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/anishagrawal/Desktop/Development/parrot/venv/lib/python3.11/site-packages (from matplotlib) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/anishagrawal/Desktop/Development/parrot/venv/lib/python3.11/site-packages (from matplotlib) (4.53.1)\r\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/anishagrawal/Desktop/Development/parrot/venv/lib/python3.11/site-packages (from matplotlib) (1.4.5)\r\n",
      "Requirement already satisfied: numpy>=1.23 in /Users/anishagrawal/Desktop/Development/parrot/venv/lib/python3.11/site-packages (from matplotlib) (2.0.0)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/anishagrawal/Desktop/Development/parrot/venv/lib/python3.11/site-packages (from matplotlib) (24.1)\r\n",
      "Requirement already satisfied: pillow>=8 in /Users/anishagrawal/Desktop/Development/parrot/venv/lib/python3.11/site-packages (from matplotlib) (10.4.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/anishagrawal/Desktop/Development/parrot/venv/lib/python3.11/site-packages (from matplotlib) (3.1.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/anishagrawal/Desktop/Development/parrot/venv/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\r\n",
      "Requirement already satisfied: more-itertools>=8.5.0 in /Users/anishagrawal/Desktop/Development/parrot/venv/lib/python3.11/site-packages (from inflect) (10.3.0)\r\n",
      "Requirement already satisfied: typeguard>=4.0.1 in /Users/anishagrawal/Desktop/Development/parrot/venv/lib/python3.11/site-packages (from inflect) (4.3.0)\r\n",
      "Requirement already satisfied: isodate in /Users/anishagrawal/Desktop/Development/parrot/venv/lib/python3.11/site-packages (from openapi-core) (0.6.1)\r\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.18.0 in /Users/anishagrawal/Desktop/Development/parrot/venv/lib/python3.11/site-packages (from openapi-core) (4.22.0)\r\n",
      "Requirement already satisfied: jsonschema-path<0.4.0,>=0.3.1 in /Users/anishagrawal/Desktop/Development/parrot/venv/lib/python3.11/site-packages (from openapi-core) (0.3.3)\r\n",
      "Requirement already satisfied: openapi-schema-validator<0.7.0,>=0.6.0 in /Users/anishagrawal/Desktop/Development/parrot/venv/lib/python3.11/site-packages (from openapi-core) (0.6.2)\r\n",
      "Requirement already satisfied: openapi-spec-validator<0.8.0,>=0.7.1 in /Users/anishagrawal/Desktop/Development/parrot/venv/lib/python3.11/site-packages (from openapi-core) (0.7.1)\r\n",
      "Requirement already satisfied: parse in /Users/anishagrawal/Desktop/Development/parrot/venv/lib/python3.11/site-packages (from openapi-core) (1.20.2)\r\n",
      "Requirement already satisfied: werkzeug in /Users/anishagrawal/Desktop/Development/parrot/venv/lib/python3.11/site-packages (from openapi-core) (3.0.3)\r\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Users/anishagrawal/Desktop/Development/parrot/venv/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.18.0->openapi-core) (23.2.0)\r\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/anishagrawal/Desktop/Development/parrot/venv/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.18.0->openapi-core) (2023.12.1)\r\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/anishagrawal/Desktop/Development/parrot/venv/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.18.0->openapi-core) (0.35.1)\r\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/anishagrawal/Desktop/Development/parrot/venv/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.18.0->openapi-core) (0.18.1)\r\n",
      "Requirement already satisfied: PyYAML>=5.1 in /Users/anishagrawal/Desktop/Development/parrot/venv/lib/python3.11/site-packages (from jsonschema-path<0.4.0,>=0.3.1->openapi-core) (6.0.1)\r\n",
      "Requirement already satisfied: pathable<0.5.0,>=0.4.1 in /Users/anishagrawal/Desktop/Development/parrot/venv/lib/python3.11/site-packages (from jsonschema-path<0.4.0,>=0.3.1->openapi-core) (0.4.3)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /Users/anishagrawal/Desktop/Development/parrot/venv/lib/python3.11/site-packages (from jsonschema-path<0.4.0,>=0.3.1->openapi-core) (2.32.3)\r\n",
      "Requirement already satisfied: rfc3339-validator in /Users/anishagrawal/Desktop/Development/parrot/venv/lib/python3.11/site-packages (from openapi-schema-validator<0.7.0,>=0.6.0->openapi-core) (0.1.4)\r\n",
      "Requirement already satisfied: lazy-object-proxy<2.0.0,>=1.7.1 in /Users/anishagrawal/Desktop/Development/parrot/venv/lib/python3.11/site-packages (from openapi-spec-validator<0.8.0,>=0.7.1->openapi-core) (1.10.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/anishagrawal/Desktop/Development/parrot/venv/lib/python3.11/site-packages (from werkzeug->openapi-core) (2.1.5)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/anishagrawal/Desktop/Development/parrot/venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.31.0->jsonschema-path<0.4.0,>=0.3.1->openapi-core) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/anishagrawal/Desktop/Development/parrot/venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.31.0->jsonschema-path<0.4.0,>=0.3.1->openapi-core) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/anishagrawal/Desktop/Development/parrot/venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.31.0->jsonschema-path<0.4.0,>=0.3.1->openapi-core) (2.2.2)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/anishagrawal/Desktop/Development/parrot/venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.31.0->jsonschema-path<0.4.0,>=0.3.1->openapi-core) (2024.7.4)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip available: \u001B[0m\u001B[31;49m22.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.1.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T05:02:03.252551Z",
     "start_time": "2024-07-09T05:02:03.250343Z"
    }
   },
   "outputs": [],
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-09T05:02:03.255312Z",
     "start_time": "2024-07-09T05:02:03.253284Z"
    }
   },
   "source": [
    "# parse openapi\n",
    "import json\n",
    "import jsonref\n",
    "\n",
    "def parse_spec(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return jsonref.load(file)"
   ],
   "outputs": [],
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import List, Optional\n",
    "\n",
    "\n",
    "class GraphNode(BaseModel):\n",
    "    asset_name: str\n",
    "    dependent_assets: List[str]\n",
    "    inputs: List[str]\n",
    "    route: str\n",
    "    method: str\n",
    "    tag: Optional[str]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T05:02:03.260042Z",
     "start_time": "2024-07-09T05:02:03.256644Z"
    }
   },
   "outputs": [],
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "source": [
    "# helpers\n",
    "import re\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import re\n",
    "from inflect import engine\n",
    "\n",
    "def resolve_schema_ref(spec, schema):\n",
    "    if isinstance(schema, dict):\n",
    "        # if '$ref' in schema:\n",
    "        #     ref = schema['$ref']\n",
    "        #     parts = ref.split('/')\n",
    "        #     current = spec\n",
    "        #     for part in parts[1:]:  # Skip the first '#' part\n",
    "        #         current = current[part]\n",
    "        #     return resolve_schema_ref(spec, current)\n",
    "\n",
    "        resolved_schema = {}\n",
    "        for key, value in schema.items():\n",
    "            if key in ['oneOf', 'allOf', 'anyOf']:\n",
    "                resolved_schema[key] = [resolve_schema_ref(spec, item) for item in value]\n",
    "            elif isinstance(value, dict):\n",
    "                resolved_schema[key] = resolve_schema_ref(spec, value)\n",
    "            elif isinstance(value, list):\n",
    "                resolved_schema[key] = [resolve_schema_ref(spec, item) if isinstance(item, dict) else item for item in value]\n",
    "            else:\n",
    "                resolved_schema[key] = value\n",
    "        return resolved_schema\n",
    "    elif isinstance(schema, list):\n",
    "        return [resolve_schema_ref(spec, item) for item in schema]\n",
    "    else:\n",
    "        return schema\n",
    "\n",
    "def standardize_asset_name(name: str) -> str:\n",
    "    # Initialize inflect engine for handling plurals\n",
    "    p = engine()\n",
    "\n",
    "    # Convert to lowercase and replace underscores with dashes\n",
    "    name = name.lower().replace('_', '-')\n",
    "    name = name.lower().replace(' ', '-')\n",
    "\n",
    "    # Remove any non-alphanumeric characters (except dashes)\n",
    "    name = re.sub(r'[^a-z0-9-]', '', name)\n",
    "\n",
    "    # Split the name into parts\n",
    "    parts = name.split('-')\n",
    "\n",
    "    # Singularize each part\n",
    "    invariant_words = {'synthesis', 'analysis', 'basis', 'thesis'}\n",
    "\n",
    "    parts = [part if part in invariant_words else (p.singular_noun(part) or part) for part in parts]\n",
    "\n",
    "    # Join the parts back together\n",
    "    standardized_name = '-'.join(parts)\n",
    "\n",
    "    # Remove 'id' or 'ids' if it's at the end of the name\n",
    "    standardized_name = re.sub(r'-ids?$', '', standardized_name)\n",
    "    return standardized_name\n",
    "\n",
    "def get_last_route_segment(route: str) -> str:\n",
    "    # Split the route by '/' and get the last non-empty segment\n",
    "    segments = route.strip('/').split('/')\n",
    "    last_segment = segments[-1] if segments else ''\n",
    "\n",
    "    # If the last segment is surrounded by curly braces, remove them\n",
    "    return re.sub(r'^\\{(.*)\\}$', r'\\1', last_segment)\n",
    "\n",
    "def last_part_has_id(route: str) -> bool:\n",
    "    # Split the route into parts\n",
    "    parts = route.strip('/').split('/')\n",
    "\n",
    "    # Get the last part\n",
    "    last_part = parts[-1] if parts else ''\n",
    "\n",
    "    # Check if the last part is enclosed in curly braces or ends with '_id'\n",
    "    return bool(re.match(r'^\\{.*\\}$', last_part) or last_part.endswith('_id'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T05:02:03.265643Z",
     "start_time": "2024-07-09T05:02:03.260697Z"
    }
   },
   "outputs": [],
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "def organize_resources(spec):\n",
    "    node_registry = {}\n",
    "\n",
    "    get_assets = set()\n",
    "    dependent_assets = set()\n",
    "    all_tags = set()\n",
    "\n",
    "    for path, methods in spec['paths'].items():\n",
    "        if last_part_has_id(path):\n",
    "            continue\n",
    "\n",
    "        for method, details in methods.items():\n",
    "            if method in [\"get\"]:\n",
    "                get_assets.add(standardize_asset_name(get_last_route_segment(path)))\n",
    "\n",
    "            if method not in [\"post\"] or last_part_has_id(path) : # maybe add `patch`\n",
    "                continue\n",
    "\n",
    "            tags = details.get(\"tags\")\n",
    "\n",
    "            dependents = set()\n",
    "            inputs = set()\n",
    "\n",
    "            bad_ids = [\"account_id\", \"x-selected-account-id\"]\n",
    "\n",
    "            def handle_properties(_properties):\n",
    "                for _input in _properties:\n",
    "                    handle_input(_input)\n",
    "\n",
    "\n",
    "            def handle_input(_input):\n",
    "                if \"id\" in _input and _input not in bad_ids:\n",
    "                    dependents.add(standardize_asset_name(_input))\n",
    "\n",
    "                inputs.add(_input)\n",
    "\n",
    "            # get ids from request body\n",
    "            body = details.get(\"requestBody\")\n",
    "            if body:\n",
    "                try:\n",
    "                    content = details[\"requestBody\"][\"content\"]\n",
    "                    pointer = content.get(\"application/json\", None)\n",
    "                    if not pointer:\n",
    "                        pointer = content[\"multipart/form-data\"]\n",
    "                    ref = pointer[\"schema\"]\n",
    "                    \n",
    "                    print(ref)\n",
    "                    request_body_schema = resolve_schema_ref(spec, ref)\n",
    "\n",
    "                    # properties\n",
    "                    properties = request_body_schema.get(\"properties\", None)\n",
    "                    if properties:\n",
    "                        handle_properties(properties)\n",
    "\n",
    "                    # nestings\n",
    "                    nested_patterns = [\"allOf\", \"oneOf\"]\n",
    "                    for pat in nested_patterns:\n",
    "                        if pat in request_body_schema:\n",
    "                            for prop in request_body_schema[pat]:\n",
    "                                if prop.get(\"properties\", None):\n",
    "                                    handle_properties(prop[\"properties\"])\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error parsing request body {path}\", e)\n",
    "\n",
    "            # get ids from parameters\n",
    "            params = details.get(\"parameters\")\n",
    "\n",
    "            if params:\n",
    "                try:\n",
    "                    for param in params:\n",
    "                        if param.get(\"name\", None):\n",
    "                            name = param[\"name\"]\n",
    "                            handle_input(name)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error parsing parameters {path}\", e)\n",
    "\n",
    "            # get ids from response\n",
    "            # responses = details.get(\"responses\")\n",
    "            #\n",
    "            # if responses:\n",
    "            #     try:\n",
    "            #         success_ref = responses[\"200\"][\"content\"][\"application/json\"][\"schema\"]\n",
    "            #         success_resp_schema = resolve_schema_ref(spec, success_ref)\n",
    "            #\n",
    "            #         properties = success_resp_schema.get(\"properties\", None)\n",
    "            #         if properties:\n",
    "            #             handle_properties(properties)\n",
    "            #\n",
    "            #     except Exception as e:\n",
    "            #         print(f\"Error parsing responses {path}\", e)\n",
    "\n",
    "            dependent_assets.update(dependents)\n",
    "\n",
    "            _tag = tags[0] if tags and len(tags) > 0 else None\n",
    "            all_tags.add(standardize_asset_name(_tag))\n",
    "\n",
    "            curr_asset = standardize_asset_name(get_last_route_segment(path))\n",
    "            new_node = GraphNode(\n",
    "                asset_name=curr_asset,\n",
    "                dependent_assets=list(dependents),\n",
    "                inputs=list(inputs),\n",
    "                route=path,\n",
    "                method=method,\n",
    "                tag=_tag,\n",
    "            )\n",
    "\n",
    "            if curr_asset not in node_registry:\n",
    "                node_registry[curr_asset] = new_node\n",
    "            elif len(node_registry[curr_asset].dependent_assets) < len(dependents):\n",
    "                node_registry[curr_asset] = new_node\n",
    "\n",
    "    # print(dependent_assets)\n",
    "    # print(get_assets)\n",
    "    # print(all_tags)\n",
    "    _nodes = list(node_registry.values())\n",
    "    real_nodes = []\n",
    "    for node in _nodes:\n",
    "        curr_asset = node.asset_name\n",
    "        if curr_asset in get_assets or curr_asset in dependent_assets or curr_asset in all_tags:\n",
    "            real_nodes.append(node)\n",
    "        else:\n",
    "            print(\"removing...\", node.asset_name)\n",
    "\n",
    "    return real_nodes"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T05:02:03.272607Z",
     "start_time": "2024-07-09T05:02:03.266479Z"
    }
   },
   "outputs": [],
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "source": [
    "from networkx import DiGraph\n",
    "from typing import List, Dict\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "def build_dependency_tree(_nodes: List[GraphNode]) -> DiGraph:\n",
    "    _graph = nx.DiGraph()  # Directed graph allows a child to have multiple parents\n",
    "\n",
    "    # Create all nodes\n",
    "    for graph_node in _nodes:\n",
    "        _graph.add_node(graph_node.asset_name)\n",
    "\n",
    "    # Create edges based on dependencies\n",
    "    for graph_node in _nodes:\n",
    "        for dependent_asset in graph_node.dependent_assets:\n",
    "            _graph.add_edge(dependent_asset, graph_node.asset_name)\n",
    "        # print(\"-\" * 50)\n",
    "        # print(graph_node.asset_name)\n",
    "        # print(\"children:\", graph_node.dependent_assets)\n",
    "\n",
    "    return _graph"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T05:02:03.275489Z",
     "start_time": "2024-07-09T05:02:03.273315Z"
    }
   },
   "outputs": [],
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "source": [
    "spec = parse_spec('v4-sgp-spec-07-04-2024.json')\n",
    "nodes = organize_resources(spec)\n",
    "\n",
    "print(nodes)\n",
    "graph = build_dependency_tree(nodes)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T05:02:03.328172Z",
     "start_time": "2024-07-09T05:02:03.276089Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'properties': {'knowledge_base_name': {'type': 'string', 'title': 'Knowledge Base Name', 'description': 'A unique name for the knowledge base'}, 'embedding_config': {'allOf': [{'anyOf': [{'properties': {'type': {'type': 'string', 'enum': ['models_api'], 'title': 'Type', 'description': 'The type of the embedding configuration.'}, 'model_deployment_id': {'type': 'string', 'title': 'Model Deployment Id', 'description': 'The ID of the deployment of the created model in the Models API V3.'}}, 'type': 'object', 'required': ['type', 'model_deployment_id'], 'title': 'EmbeddingConfigModelsAPI'}, {'properties': {'type': {'type': 'string', 'enum': ['base'], 'title': 'Type', 'description': 'The type of the embedding configuration.', 'default': 'base'}, 'embedding_model': {'allOf': [{'type': 'string', 'enum': ['sentence-transformers/all-MiniLM-L12-v2', 'sentence-transformers/multi-qa-distilbert-cos-v1', 'sentence-transformers/paraphrase-multilingual-mpnet-base-v2', 'openai/text-embedding-ada-002', 'openai/text-embedding-3-small', 'openai/text-embedding-3-large', 'embed-english-v3.0', 'embed-english-light-v3.0', 'embed-multilingual-v3.0'], 'title': 'EmbeddingModelName', 'description': 'An enumeration.'}], 'description': \"The name of the base embedding model to use. To use custom models, change to type 'models'.\"}}, 'type': 'object', 'required': ['embedding_model'], 'title': 'EmbeddingConfigBase'}], 'title': 'EmbeddingConfig'}], 'title': 'Embedding Config', 'description': 'The configuration of the embedding'}, 'account_id': {'type': 'string', 'title': 'Account Id', 'description': 'Account to create knowledge base in. If you have access to more than one account, you must specify an account_id'}, 'metadata': {'type': 'object', 'title': 'Metadata', 'description': 'Metadata associated with the knowledge base'}}, 'type': 'object', 'required': ['knowledge_base_name', 'embedding_config'], 'title': 'CreateKnowledgeBaseRequestV2'}\n",
      "{'properties': {'query': {'type': 'string', 'title': 'Query', 'description': 'The natural language query to be answered by referencing the data ingested into the knowledge base'}, 'top_k': {'type': 'integer', 'maximum': 10000.0, 'exclusiveMinimum': 0.0, 'title': 'Top K', 'description': 'Number of chunks to return. Must be greater than 0 if specified. If not specified, all chunks will be returned.'}, 'include_embeddings': {'type': 'boolean', 'title': 'Include Embeddings', 'description': 'Whether or not to include the embeddings for each chunk', 'default': True}, 'metadata_filters': {'type': 'object', 'title': 'Metadata Filters', 'description': 'Optional filter by metadata fields, encoded as a JSON object'}, 'verbose': {'type': 'boolean', 'title': 'Verbose', 'description': 'Enable or disable verbose logging', 'default': False}}, 'type': 'object', 'required': ['query', 'top_k'], 'title': 'QueryKnowledgeBaseRequestV2'}\n",
      "{'anyOf': [{'properties': {'data_source_config': {'allOf': [{'oneOf': [{'properties': {'source': {'type': 'string', 'enum': ['S3'], 'title': 'Source'}, 's3_bucket': {'type': 'string', 'title': 'S3 Bucket', 'description': 'Name of the S3 bucket where the data is stored.'}, 's3_prefix': {'type': 'string', 'title': 'S3 Prefix', 'description': 'Prefix of the S3 bucket where the data is stored. If not specified, the entire bucket will be used.', 'default': ''}, 'aws_region': {'type': 'string', 'title': 'Aws Region', 'description': 'AWS region where the S3 bucket is located.'}, 'aws_account_id': {'type': 'string', 'pattern': '^\\\\d{12}$', 'title': 'Aws Account Id', 'description': 'AWS account ID that owns the S3 bucket.'}}, 'type': 'object', 'required': ['source', 's3_bucket', 'aws_region', 'aws_account_id'], 'title': 'S3 DataSource Config'}, {'properties': {'source': {'type': 'string', 'enum': ['SharePoint'], 'title': 'Source'}, 'client_id': {'type': 'string', 'title': 'Client Id', 'description': 'Client ID associated with this SharePoint site'}, 'tenant_id': {'type': 'string', 'title': 'Tenant Id', 'description': 'Tenant ID that the SharePoint site is within'}, 'site_id': {'type': 'string', 'title': 'Site Id', 'description': 'Site ID for this SharePoint site, can be found at https://[hostname].sharepoint.com/sites/[site name]/_api/site/id'}, 'folder_path': {'type': 'string', 'title': 'Folder Path', 'description': \"Nested folder path to read files from the root of the site. Please omit the leading slash. Example: 'Documents/sub_directory'\", 'default': ''}, 'recursive': {'type': 'boolean', 'title': 'Recursive', 'description': 'Recurse through the folder contents, default is True.', 'default': True}}, 'type': 'object', 'required': ['source', 'client_id', 'tenant_id', 'site_id'], 'title': 'SharePoint DataSource Config'}, {'properties': {'source': {'type': 'string', 'enum': ['GoogleDrive'], 'title': 'Source'}, 'drive_id': {'type': 'string', 'title': 'Drive Id', 'description': 'ID associated with the Google Drive to retrieve contents from'}}, 'type': 'object', 'required': ['source', 'drive_id'], 'title': 'Google Drive DataSource Config'}, {'properties': {'source': {'type': 'string', 'enum': ['AzureBlobStorage'], 'title': 'Source'}, 'container_url': {'type': 'string', 'title': 'Container Url', 'description': \"The full URL of the container such as 'https://your-account-name.blob.core.windows.net/your-container-name'\"}}, 'type': 'object', 'required': ['source', 'container_url'], 'title': 'Azure Blob Storage DataSource Config'}, {'properties': {'source': {'type': 'string', 'enum': ['Confluence'], 'title': 'Source'}, 'space_key': {'type': 'string', 'title': 'Space Key', 'description': 'Confluence space key to retrieve contents from. See https://support.atlassian.com/confluence-cloud/docs/choose-a-space-key'}}, 'type': 'object', 'required': ['source', 'space_key'], 'title': 'Confluence DataSource Config'}, {'properties': {'source': {'type': 'string', 'enum': ['Slack'], 'title': 'Source'}, 'channel_id': {'type': 'string', 'title': 'Channel Id', 'description': \"Slack Channel or Conversation ID to retrieve history from. Open channel details and find the ID at bottom of 'About' section.\"}}, 'type': 'object', 'required': ['source', 'channel_id'], 'title': 'Slack DataSource Config'}], 'title': 'RemoteDataSourceConfig', 'discriminator': {'propertyName': 'source', 'mapping': {'S3': '#/components/schemas/S3DataSourceConfig', 'SharePoint': '#/components/schemas/SharePointDataSourceConfig', 'GoogleDrive': '#/components/schemas/GoogleDriveDataSourceConfig', 'AzureBlobStorage': '#/components/schemas/AzureBlobStorageDataSourceConfig', 'Confluence': '#/components/schemas/ConfluenceDataSourceConfig', 'Slack': '#/components/schemas/SlackDataSourceConfig'}}}], 'title': 'Data Source Config', 'description': 'Configuration for the data source which describes where to find the data.'}, 'data_source_auth_config': {'allOf': [{'oneOf': [{'properties': {'encrypted': {'type': 'boolean', 'title': 'Encrypted', 'default': False}, 'source': {'type': 'string', 'enum': ['SharePoint'], 'title': 'Source'}, 'client_secret': {'type': 'string', 'title': 'Client Secret', 'description': 'Secret for the app registration associated with this SharePoint site'}}, 'type': 'object', 'required': ['source', 'client_secret'], 'title': 'SharePoint DataSource Auth Config'}, {'properties': {'encrypted': {'type': 'boolean', 'title': 'Encrypted', 'default': False}, 'source': {'type': 'string', 'enum': ['AzureBlobStorage'], 'title': 'Source'}, 'blob_sas_token': {'type': 'string', 'title': 'Blob Sas Token', 'description': 'Shared Access Signature token for the Azure Blob Storage container'}}, 'type': 'object', 'required': ['source', 'blob_sas_token'], 'title': 'Azure DataSource Auth Config'}, {'properties': {'encrypted': {'type': 'boolean', 'title': 'Encrypted', 'default': False}, 'source': {'type': 'string', 'enum': ['GoogleDrive'], 'title': 'Source'}, 'client_email': {'type': 'string', 'title': 'Client Email', 'description': 'Client email to use for google drive, set to override client email set in env vars'}, 'private_key': {'type': 'string', 'title': 'Private Key', 'description': 'Private key to use for google drive, set to override private key set in env vars'}, 'token_uri': {'type': 'string', 'title': 'Token Uri', 'description': 'Token uri to use for google drive, set to override token uri set in env vars'}, 'client_id': {'type': 'string', 'title': 'Client Id', 'description': 'Client id to use for google drive, set to override client id set in env vars'}}, 'type': 'object', 'required': ['source', 'client_email', 'private_key', 'token_uri', 'client_id'], 'title': 'Google Drive DataSource Auth Config'}, {'properties': {'encrypted': {'type': 'boolean', 'title': 'Encrypted', 'default': False}, 'source': {'type': 'string', 'enum': ['S3'], 'title': 'Source'}, 's3_role': {'type': 'string', 'title': 'S3 Role', 'description': 'Name of the role that a client will be initialized via AssumeRole of AWS sts'}, 'external_id': {'type': 'string', 'title': 'External Id', 'description': 'External ID defined by the customer for the IAM role'}}, 'type': 'object', 'required': ['source'], 'title': 'S3 DataSource Auth Config'}, {'properties': {'encrypted': {'type': 'boolean', 'title': 'Encrypted', 'default': False}, 'source': {'type': 'string', 'enum': ['Confluence'], 'title': 'Source'}, 'client_email': {'type': 'string', 'title': 'Client Email', 'description': 'Client email to use for Confluence, set to override client email set in env vars.'}, 'api_key': {'type': 'string', 'title': 'Api Key', 'description': 'API key to use for Confluence, set this to override api key configured in env vars.'}, 'atlassian_domain': {'type': 'string', 'title': 'Atlassian Domain', 'description': \"Your Confluence API server's full domain, set to override domain configured in env vars. E.g. 'https://[your-company].atlassian.net'\"}}, 'type': 'object', 'required': ['source', 'client_email', 'api_key', 'atlassian_domain'], 'title': 'Confluence DataSource Auth Config'}, {'properties': {'encrypted': {'type': 'boolean', 'title': 'Encrypted', 'default': False}, 'source': {'type': 'string', 'enum': ['Slack'], 'title': 'Source'}, 'bot_token': {'type': 'string', 'title': 'Bot Token', 'description': \"Your Slack app's Bot OAuth token. See https://api.slack.com/quickstart\"}}, 'type': 'object', 'required': ['source', 'bot_token'], 'title': 'Slack DataSource Auth Config'}], 'title': 'DataSourceAuthConfig', 'discriminator': {'propertyName': 'source', 'mapping': {'SharePoint': '#/components/schemas/SharePointDataSourceAuthConfig', 'AzureBlobStorage': '#/components/schemas/AzureBlobStorageDataSourceAuthConfig', 'GoogleDrive': '#/components/schemas/GoogleDriveDataSourceAuthConfig', 'S3': '#/components/schemas/S3DataSourceAuthConfig', 'Confluence': '#/components/schemas/ConfluenceDataSourceAuthConfig', 'Slack': '#/components/schemas/SlackDataSourceAuthConfig'}}}], 'title': 'Data Source Auth Config', 'description': 'Configuration for the data source which describes how to authenticate to the data source.'}, 'chunking_strategy_config': {'allOf': [{'oneOf': [{'properties': {'strategy': {'type': 'string', 'enum': ['character'], 'title': 'Strategy'}, 'separator': {'type': 'string', 'title': 'Separator', 'description': 'Character designating breaks in input data. Text data will first be split into sections by this separator, then each section will be split into chunks of size `chunk_size`.', 'default': '\\n\\n'}, 'chunk_size': {'type': 'integer', 'minimum': 1.0, 'title': 'Chunk Size', 'description': 'Maximum number of characters in each chunk. If not specified, a chunk size of 1000 will be used.', 'default': 1000}, 'chunk_overlap': {'type': 'integer', 'minimum': 0.0, 'title': 'Chunk Overlap', 'description': \"Number of characters to overlap between chunks. If not specified, an overlap of 200 will be used. For example if the chunk size is 3 and the overlap size is 1, and the text to chunk is 'abcde', the chunks will be 'abc', 'cde'.\", 'default': 200}}, 'type': 'object', 'required': ['strategy'], 'title': 'CharacterChunkingStrategyConfig'}, {'properties': {'strategy': {'type': 'string', 'enum': ['token'], 'title': 'Strategy'}, 'separator': {'type': 'string', 'title': 'Separator', 'description': 'Character designating breaks in input data. Text data will first be split into sections by this separator, then each section will be split into chunks of size `chunk_size`.', 'default': '\\n\\n'}, 'target_chunk_size': {'type': 'integer', 'minimum': 1.0, 'title': 'Target Chunk Size', 'description': 'Target number of tokens in each chunk. If not specified, a target chunk size of 200 will be used.', 'default': 200}, 'max_chunk_size': {'type': 'integer', 'minimum': 1.0, 'title': 'Max Chunk Size', 'description': 'Maximum number of tokens in each chunk. If not specified, a maximum chunk size of 600 will be used.', 'default': 600}, 'chunk_overlap': {'type': 'integer', 'minimum': 0.0, 'title': 'Chunk Overlap', 'description': 'Number of tokens to overlap between chunks. If not specified, an overlap of 0 will be used. Not this if only followed approximately.', 'default': 0}}, 'type': 'object', 'required': ['strategy'], 'title': 'TokenChunkingStrategyConfig'}, {'properties': {'strategy': {'type': 'string', 'enum': ['custom'], 'title': 'Strategy'}, 'endpoint': {'type': 'string', 'title': 'Endpoint', 'description': 'Endpoint path to call for custom chunking'}, 'params': {'type': 'object', 'title': 'Params', 'description': 'Parameters that will be appended to the body of the request for the chunk.', 'default': {}}}, 'type': 'object', 'required': ['strategy', 'endpoint'], 'title': 'CustomChunkingStrategyConfig'}], 'title': 'ChunkingStrategyConfig', 'discriminator': {'propertyName': 'strategy', 'mapping': {'character': '#/components/schemas/CharacterChunkingStrategyConfig', 'token': '#/components/schemas/TokenChunkingStrategyConfig', 'custom': '#/components/schemas/CustomChunkingStrategyConfig'}}}], 'title': 'Chunking Strategy Config', 'description': 'Configuration for the chunking strategy which describes how to chunk the data.'}, 'force_reupload': {'type': 'boolean', 'title': 'Force Reupload', 'description': 'Force reingest, regardless the change of the source file.', 'default': False}}, 'type': 'object', 'required': ['data_source_config'], 'title': 'DataSource Upload Request'}, {'properties': {'data_source_config': {'allOf': [{'properties': {'source': {'type': 'string', 'enum': ['LocalChunks'], 'title': 'Source'}, 'artifact_name': {'type': 'string', 'title': 'Artifact Name', 'description': 'The file name assigned to the artifact, containing a file extension. Adding an extension is mandatory, to allow detecting file types for text extraction.'}, 'artifact_uri': {'type': 'string', 'title': 'Artifact Uri', 'description': 'A unique identifier for an artifact within the knowledge base, such as full path in a directory or file system.'}, 'deduplication_strategy': {'allOf': [{'type': 'string', 'enum': ['Overwrite', 'Fail'], 'title': 'DeduplicationStrategy', 'description': 'An enumeration.'}], 'description': 'Action to take if an artifact with the same name already exists in the knowledge base. Can be either Overwrite (default) or Fail.', 'default': 'Overwrite'}}, 'type': 'object', 'required': ['source', 'artifact_name', 'artifact_uri'], 'title': 'LocalChunksSourceConfig'}], 'title': 'Data Source Config', 'description': 'Configuration for the data source which describes where to find the data.'}, 'chunks': {'items': {'properties': {'text': {'type': 'string', 'title': 'Text', 'description': 'Associated text of the chunk.'}, 'chunk_position': {'type': 'integer', 'title': 'Chunk Position', 'description': 'Position of the chunk in the artifact.'}, 'metadata': {'type': 'object', 'title': 'Metadata', 'description': 'Additional metadata associated with the chunk.', 'default': {}}}, 'type': 'object', 'required': ['text', 'chunk_position'], 'title': 'ArtifactChunkUpload'}, 'type': 'array', 'title': 'Chunks', 'description': 'List of chunks.'}, 'force_reupload': {'type': 'boolean', 'title': 'Force Reupload', 'description': 'Force reingest, regardless the change of the source file.', 'default': False}}, 'type': 'object', 'required': ['data_source_config'], 'title': 'Local Chunks Upload Request'}, {'properties': {'data_source_id': {'type': 'string', 'title': 'Data Source Id', 'description': 'Id of the data source to fetch.'}, 'chunking_strategy_config': {'allOf': [{'oneOf': [{'properties': {'strategy': {'type': 'string', 'enum': ['character'], 'title': 'Strategy'}, 'separator': {'type': 'string', 'title': 'Separator', 'description': 'Character designating breaks in input data. Text data will first be split into sections by this separator, then each section will be split into chunks of size `chunk_size`.', 'default': '\\n\\n'}, 'chunk_size': {'type': 'integer', 'minimum': 1.0, 'title': 'Chunk Size', 'description': 'Maximum number of characters in each chunk. If not specified, a chunk size of 1000 will be used.', 'default': 1000}, 'chunk_overlap': {'type': 'integer', 'minimum': 0.0, 'title': 'Chunk Overlap', 'description': \"Number of characters to overlap between chunks. If not specified, an overlap of 200 will be used. For example if the chunk size is 3 and the overlap size is 1, and the text to chunk is 'abcde', the chunks will be 'abc', 'cde'.\", 'default': 200}}, 'type': 'object', 'required': ['strategy'], 'title': 'CharacterChunkingStrategyConfig'}, {'properties': {'strategy': {'type': 'string', 'enum': ['token'], 'title': 'Strategy'}, 'separator': {'type': 'string', 'title': 'Separator', 'description': 'Character designating breaks in input data. Text data will first be split into sections by this separator, then each section will be split into chunks of size `chunk_size`.', 'default': '\\n\\n'}, 'target_chunk_size': {'type': 'integer', 'minimum': 1.0, 'title': 'Target Chunk Size', 'description': 'Target number of tokens in each chunk. If not specified, a target chunk size of 200 will be used.', 'default': 200}, 'max_chunk_size': {'type': 'integer', 'minimum': 1.0, 'title': 'Max Chunk Size', 'description': 'Maximum number of tokens in each chunk. If not specified, a maximum chunk size of 600 will be used.', 'default': 600}, 'chunk_overlap': {'type': 'integer', 'minimum': 0.0, 'title': 'Chunk Overlap', 'description': 'Number of tokens to overlap between chunks. If not specified, an overlap of 0 will be used. Not this if only followed approximately.', 'default': 0}}, 'type': 'object', 'required': ['strategy'], 'title': 'TokenChunkingStrategyConfig'}, {'properties': {'strategy': {'type': 'string', 'enum': ['custom'], 'title': 'Strategy'}, 'endpoint': {'type': 'string', 'title': 'Endpoint', 'description': 'Endpoint path to call for custom chunking'}, 'params': {'type': 'object', 'title': 'Params', 'description': 'Parameters that will be appended to the body of the request for the chunk.', 'default': {}}}, 'type': 'object', 'required': ['strategy', 'endpoint'], 'title': 'CustomChunkingStrategyConfig'}], 'title': 'ChunkingStrategyConfig', 'discriminator': {'propertyName': 'strategy', 'mapping': {'character': '#/components/schemas/CharacterChunkingStrategyConfig', 'token': '#/components/schemas/TokenChunkingStrategyConfig', 'custom': '#/components/schemas/CustomChunkingStrategyConfig'}}}], 'title': 'Chunking Strategy Config', 'description': 'Configuration for the chunking strategy which describes how to chunk the data.'}, 'force_reupload': {'type': 'boolean', 'title': 'Force Reupload', 'description': 'Force reingest, regardless the change of the source file.', 'default': False}}, 'type': 'object', 'required': ['data_source_id', 'chunking_strategy_config'], 'title': 'DataSource Upload Request'}], 'title': 'CreateKnowledgeBaseV2UploadRequest'}\n",
      "{'properties': {'query': {'type': 'string', 'title': 'Query', 'description': 'Natural language query to re-rank chunks against. If a vector store query was originally used to retrieve these chunks, please use the same query for this ranking'}, 'relevant_chunks': {'items': {'properties': {'chunk_id': {'type': 'string', 'title': 'Chunk Id', 'description': 'The unique ID of the chunk with embedding'}, 'text': {'type': 'string', 'title': 'Text', 'description': 'The text associated with the chunk'}, 'embedding': {'items': {'type': 'number'}, 'type': 'array', 'title': 'Embedding', 'description': 'The vector embedding of the text associated with the chunk'}, 'metadata': {'type': 'object', 'title': 'Metadata', 'description': 'Any additional key value pairs of information stored by you on the chunk with embedding', 'default': {}}, 'user_supplied_metadata': {'type': 'object', 'title': 'User Supplied Metadata', 'description': 'Any additional key value pairs of information returned from the custom chunking.', 'default': {}}, 'attachment_url': {'type': 'string', 'title': 'Attachment Url', 'description': 'Original attachment URL from which this chunk got its data from'}, 'title': {'type': 'string', 'title': 'Title', 'description': 'Title for this chunk, for example the file name'}, 'score': {'type': 'number', 'title': 'Score', 'description': \"A number between 0 and 1 representing how similar a chunk's embedding is to the query embedding. Higher numbers mean that this chunk with embedding is more similar.\"}}, 'type': 'object', 'required': ['chunk_id', 'text', 'score'], 'title': 'ChunkV2'}, 'type': 'array', 'title': 'Relevant Chunks', 'description': 'List of chunks to rank'}, 'rank_strategy': {'allOf': [{'oneOf': [{'properties': {'method': {'type': 'string', 'enum': ['cross_encoder'], 'const': 'cross_encoder', 'title': 'Method', 'description': 'The name of the rank strategy. Must be `cross_encoder`.', 'default': 'cross_encoder'}, 'params': {'allOf': [{'properties': {'cross_encoder_model': {'type': 'string', 'enum': ['cross-encoder/ms-marco-MiniLM-L-12-v2', 'cross-encoder/mmarco-mMiniLMv2-L12-H384-v1'], 'title': 'Cross Encoder Model', 'description': 'Cross encoder model to use when ranking. Currently supports [cross-encoder/ms-marco-MiniLM-L-12-v2](https://huggingface.co/cross-encoder/ms-marco-MiniLM-L-12-v2) and [cross-encoder/mmarco-mMiniLMv2-L12-H384-v1](https://huggingface.co/cross-encoder/mmarco-mMiniLMv2-L12-H384-v1).', 'default': 'cross-encoder/ms-marco-MiniLM-L-12-v2'}}, 'type': 'object', 'title': 'CrossEncoderRankParams'}], 'title': 'Params', 'description': 'The parameters needed for ranking.', 'default': {'cross_encoder_model': 'cross-encoder/ms-marco-MiniLM-L-12-v2'}}}, 'type': 'object', 'title': 'CrossEncoderRankStrategy'}, {'properties': {'method': {'type': 'string', 'enum': ['rouge'], 'const': 'rouge', 'title': 'Method', 'description': 'The name of the rank strategy.', 'default': 'rouge'}, 'params': {'allOf': [{'properties': {'metric': {'type': 'string', 'title': 'Metric', 'description': 'Rouge type, can be n-gram based (e.g. rouge1, rouge2) or longest common subsequence (rougeL or rougeLsum)', 'default': 'rouge2'}, 'score': {'type': 'string', 'enum': ['precision', 'recall', 'fmeasure'], 'title': 'Score', 'description': 'Metric to use from Rouge score', 'default': 'recall'}}, 'type': 'object', 'title': 'RougeRankParams'}], 'title': 'Params', 'description': 'The parameters needed for ranking.', 'default': {'metric': 'rouge2', 'score': 'recall'}}}, 'type': 'object', 'title': 'RougeRankStrategy'}, {'properties': {'method': {'type': 'string', 'enum': ['model'], 'const': 'model', 'title': 'Method', 'description': 'Use a model from Models API for ranking.', 'default': 'model'}, 'params': {'allOf': [{'properties': {'model_deployment_id': {'type': 'string', 'title': 'Model Deployment Id', 'description': 'The model deployment id of a custom model to use for reranking'}, 'base_model_name': {'type': 'string', 'title': 'Base Model Name', 'description': 'The name of a base model to use for reranking'}, 'model_params': {'type': 'object', 'title': 'Model Params'}}, 'type': 'object', 'title': 'ModelRankParams'}], 'title': 'Params', 'description': 'The parameters needed for ranking.', 'default': {'model_params': {}}}}, 'type': 'object', 'title': 'ModelRankStrategy'}], 'title': 'RankStrategy', 'discriminator': {'propertyName': 'method', 'mapping': {'cross_encoder': '#/components/schemas/CrossEncoderRankStrategy', 'rouge': '#/components/schemas/RougeRankStrategy', 'model': '#/components/schemas/ModelRankStrategy'}}}], 'title': 'Rank Strategy', 'description': 'The ranking strategy to use.\\n\\nRank strategies determine how the ranking is done, They consist of the ranking method name and additional params needed to compute the ranking.\\n\\nUse the built-in `cross_encoder` or `rouge` strategies or create a custom one with the Models API.'}, 'top_k': {'type': 'integer', 'exclusiveMinimum': 0.0, 'title': 'Top K', 'description': 'Number of chunks to return. Must be greater than 0 if specified. If not specified, all chunks will be returned.'}, 'account_id': {'type': 'string', 'title': 'Account Id', 'description': 'Account to rank chunks with. If you have access to more than one account, you must specify an account_id'}}, 'type': 'object', 'required': ['query', 'relevant_chunks', 'rank_strategy'], 'title': 'ChunksRankRequest'}\n",
      "{'properties': {'query': {'type': 'string', 'title': 'Query', 'description': 'Natural language query to resolve using the supplied chunks.'}, 'chunks': {'items': {'properties': {'chunk_id': {'type': 'string', 'title': 'Chunk Id', 'description': 'The unique ID of the chunk with embedding'}, 'text': {'type': 'string', 'title': 'Text', 'description': 'The text associated with the chunk'}, 'embedding': {'items': {'type': 'number'}, 'type': 'array', 'title': 'Embedding', 'description': 'The vector embedding of the text associated with the chunk'}, 'metadata': {'type': 'object', 'title': 'Metadata', 'description': 'Any additional key value pairs of information stored by you on the chunk with embedding', 'default': {}}, 'user_supplied_metadata': {'type': 'object', 'title': 'User Supplied Metadata', 'description': 'Any additional key value pairs of information returned from the custom chunking.', 'default': {}}, 'attachment_url': {'type': 'string', 'title': 'Attachment Url', 'description': 'Original attachment URL from which this chunk got its data from'}, 'title': {'type': 'string', 'title': 'Title', 'description': 'Title for this chunk, for example the file name'}, 'score': {'type': 'number', 'title': 'Score', 'description': \"A number between 0 and 1 representing how similar a chunk's embedding is to the query embedding. Higher numbers mean that this chunk with embedding is more similar.\"}}, 'type': 'object', 'required': ['chunk_id', 'text', 'score'], 'title': 'ChunkV2'}, 'type': 'array', 'title': 'Chunks', 'description': 'List of chunks to use to synthesize the response.'}}, 'type': 'object', 'required': ['query', 'chunks'], 'title': 'SynthesizeChunksRequest'}\n",
      "{'properties': {'model': {'type': 'string', 'enum': ['gpt-4', 'gpt-4-0613', 'gpt-4-32k', 'gpt-4-32k-0613', 'gpt-3.5-turbo', 'gpt-3.5-turbo-0613', 'gpt-3.5-turbo-16k', 'gpt-3.5-turbo-16k-0613', 'claude-instant-1', 'claude-instant-1.1', 'claude-2', 'claude-2.0'], 'title': 'Model', 'description': 'The ID of the model to use for the agent. We only support the models listed here so far.'}, 'memory_strategy': {'allOf': [{'properties': {'name': {'type': 'string', 'enum': ['last_k'], 'const': 'last_k', 'title': 'Name', 'description': \"Name of the memory strategy. Must be `last_k`.\\n\\nThis strategy truncates the message history to the last `k` messages. It is the simplest way to prevent the model's context limit from being exceeded. However, this strategy only allows the model to have short term memory. For longer term memory, please use one of the other strategies.\", 'default': 'last_k'}, 'params': {'allOf': [{'properties': {'k': {'type': 'integer', 'minimum': 1.0, 'title': 'K', 'description': 'The maximum number of previous messages to remember.'}}, 'type': 'object', 'required': ['k'], 'title': 'LastKMemoryStrategyParams'}], 'title': 'Params', 'description': 'Configuration parameters for the memory strategy.'}}, 'type': 'object', 'required': ['params'], 'title': 'Last K Memory Strategy'}], 'title': 'Memory Strategy', 'description': \"The memory strategy to use for the agent. A memory strategy is a way to prevent the underlying LLM's context limit from being exceeded. Each memory strategy uses a different technique to condense the input message list into a smaller payload for the underlying LLM.\\n\\nWe only support the Last K memory strategy right now, but will be adding new strategies soon.\"}, 'tools': {'items': {'properties': {'name': {'type': 'string', 'pattern': '^[a-zA-Z0-9_-]{1,64}$', 'title': 'Name', 'description': 'Name of the tool.\\n\\nA tool is a function that the _client application_ has at its disposal. The tool name is the name the client wishes the Agent to use to refer to this function when it decides if it wants the user to use the tool or not. Itmust be unique amongst the set of tools provided in a single API call.'}, 'description': {'type': 'string', 'title': 'Description', 'description': 'Description of the tool.\\n\\nBecause some queries are complex and may require multiple tools to complete, it is important to make these descriptions as informative as possible. If a tool is not being chosen when it should, it is common practice to tune the description of the tool to make it more apparent to the agent when the tool can be used effectively.'}, 'arguments': {'allOf': [{'properties': {'type': {'type': 'string', 'enum': ['object'], 'title': 'Type', 'description': 'Type of argument. Currently only \"object\" is supported'}, 'properties': {'additionalProperties': {'properties': {'type': {'type': 'string', 'enum': ['string', 'number', 'integer', 'boolean', 'object', 'array', 'null'], 'title': 'Type', 'description': \"The argument's type.\\n\\nThe type is used to help the Agent generate valid arguments for the tool.\\n\\nFor more information about types, see: https://json-schema.org/understanding-json-schema/reference/type.html#type-specific-keywords\"}, 'description': {'type': 'string', 'title': 'Description', 'description': 'Description of what the argument is used for.\\n\\nThis description is used to help the Agent generate sensible arguments for the tool. It is very important that this description is succinct, clear, and accurate.'}, 'default': {'type': 'string', 'title': 'Default', 'description': 'A default value for the argument if unspecified.'}, 'examples': {'items': {'type': 'string'}, 'type': 'array', 'title': 'Examples', 'description': 'Example values demonstrating how the argument should look.\\n\\nThis can be used to help the agent understand what a valid argument should look like.'}}, 'type': 'object', 'required': ['type', 'description'], 'title': 'property'}, 'type': 'object', 'title': 'Properties', 'description': 'An object where each key is the name of a keyword argument and each value is a schema used to validate that property. Each schema must have a type and description, but can also have a default value and examples.\\n\\nFor more information on how to define a valid property, visit https://json-schema.org/understanding-json-schema/reference/object.html'}}, 'type': 'object', 'required': ['type'], 'title': 'ToolArguments'}], 'title': 'Arguments', 'description': 'An JSON Schema-compliant schema for the tool arguments. To describe a function that accepts no parameters, provide the value `{\"type\": \"\"object\", \"properties\": {}}`.\\n\\nFor more information on how to define a valid JSON Schema object, visit https://json-schema.org/understanding-json-schema/reference/object.html'}}, 'type': 'object', 'required': ['name', 'description', 'arguments'], 'title': 'Tool'}, 'type': 'array', 'title': 'Tools', 'description': 'The list of specs of tools that the agent can use. Each spec must contain a `name` key set to the name of the tool, a `description` key set to the description of the tool, and an `arguments` key set to a JSON Schema compliant object describing the tool arguments.\\n\\nThe name and description of each tool is used by the agent to decide when to use certain tools. Because some queries are complex and may require multiple tools to complete, it is important to make these descriptions as informative as possible. If a tool is not being chosen when it should, it is common practice to tune the description of the tool to make it more apparent to the agent when the tool can be used effectively.\\n\\n'}, 'messages': {'items': {'oneOf': [{'properties': {'role': {'type': 'string', 'enum': ['user'], 'const': 'user', 'title': 'Role', 'description': \"The role of the message. Must be set to 'user'.\\n\\nA user message is a message from the user to the AI. This should be the message used to send end user input to the AI.\", 'default': 'user'}, 'content': {'type': 'string', 'title': 'Content', 'description': 'Text input from the user'}}, 'type': 'object', 'required': ['content'], 'title': 'User Message'}, {'properties': {'role': {'type': 'string', 'enum': ['tool'], 'const': 'tool', 'title': 'Role', 'description': \"The role of the message. Must be set to 'tool'.\\n\\nA tool message is a message the client application uses to send tool output to the AI. It should contain the name of the tool and the output from the tool encoded as text.\", 'default': 'tool'}, 'name': {'type': 'string', 'title': 'Name', 'description': 'Name of the tool'}, 'content': {'type': 'string', 'title': 'Content', 'description': 'Text output from the tool'}}, 'type': 'object', 'required': ['name', 'content'], 'title': 'Tool Message'}, {'properties': {'role': {'type': 'string', 'enum': ['agent'], 'const': 'agent', 'title': 'Role', 'description': \"The role of the message. Must be set to 'agent'.\\n\\nAn agent message is a message generated by an AI agent. It is different than an assistant message in that it can either contain a direct content output or a tool request that the client application must handle.\", 'default': 'agent'}, 'content': {'type': 'string', 'title': 'Content', 'description': 'Text output of the agent if no more tools are needed.'}, 'tool_request': {'allOf': [{'properties': {'name': {'type': 'string', 'title': 'Name', 'description': 'Name of the tool that the AI wants the client to use.'}, 'arguments': {'type': 'string', 'title': 'Arguments', 'description': 'Arguments to pass to the tool. The format must be a JSON Schema-compliant object serialized into a string.'}}, 'type': 'object', 'required': ['name', 'arguments'], 'title': 'ToolRequest'}], 'title': 'Tool Request', 'description': 'The tool request if the agent needs more information.'}}, 'type': 'object', 'title': 'Agent Message'}, {'properties': {'role': {'type': 'string', 'enum': ['system'], 'const': 'system', 'title': 'Role', 'description': \"The role of the message. Must be set to 'system'.\\n\\nA system message is different from other messages in that it does not originate from a party engaged in a user/AI conversation. Instead, it is a message that is injected by either the application or system to guide the conversation. For example, a system message may be used as initial instructions for an AI entity or to tell the AI that it did not do something correctly.\", 'default': 'system'}, 'content': {'type': 'string', 'title': 'Content', 'description': 'Text input from the system.'}}, 'type': 'object', 'required': ['content'], 'title': 'System Message'}], 'title': 'Message', 'discriminator': {'propertyName': 'role', 'mapping': {'user': '#/components/schemas/egp_api_backend__server__api__models__egp_models__UserMessage', 'tool': '#/components/schemas/ToolMessage', 'agent': '#/components/schemas/AgentMessage', 'system': '#/components/schemas/egp_api_backend__server__api__models__egp_models__SystemMessage'}}}, 'type': 'array', 'title': 'Messages', 'description': 'The list of messages in the conversation.\\n\\nExpand each message type to see how it works and when to use it. Most conversations should begin with a single `user` message.'}, 'model_parameters': {'allOf': [{'properties': {'temperature': {'type': 'number', 'maximum': 1.0, 'minimum': 0.0, 'title': 'Temperature', 'description': 'What sampling temperature to use, between [0, 1]. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. Setting temperature=0.0 will enable fully deterministic (greedy) sampling.', 'default': 0.2}, 'stop_sequences': {'items': {'type': 'string'}, 'type': 'array', 'maxItems': 4, 'title': 'Stop Sequences', 'description': 'List of up to 4 sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence.'}, 'max_tokens': {'type': 'integer', 'title': 'Max Tokens', 'description': \"The maximum number of tokens to generate in the completion. The token count of your prompt plus max_tokens cannot exceed the model's context length. If not, specified, max_tokens will be determined based on the model used: \\n| Model API family | Model API default | EGP applied default |\\n| --- | --- | --- |\\n| OpenAI Completions | [`16`](https://platform.openai.com/docs/api-reference/completions/create#max_tokens) | `context window - prompt size` |\\n| OpenAI Chat Completions | [`context window - prompt size`](https://platform.openai.com/docs/api-reference/chat/create#max_tokens) | `context window - prompt size` |\\n| LLM Engine | [`max_new_tokens`](https://github.com/scaleapi/launch-python-client/blob/207adced1c88c1c2907266fa9dd1f1ff3ec0ea5b/launch/client.py#L2910) parameter is required | `100` |\\n| Anthropic Claude 2 | [`max_tokens_to_sample`](https://docs.anthropic.com/claude/reference/complete_post) parameter is required | `10000` |\\n\"}, 'topP': {'type': 'number', 'title': 'Topp', 'description': 'The cumulative probability cutoff for token selection. Lower values mean sampling from a smaller, more top-weighted nucleus. Available for models from Anthropic, Google, Mistral, LLM Engine, and OpenAI.'}, 'topK': {'type': 'integer', 'title': 'Topk', 'description': 'Sample from the k most likely next tokens at each step. Lower k focuses on higher probability tokens. Available for models from Anthropic, Google, and LLM Engine.'}, 'frequency_penalty': {'type': 'number', 'title': 'Frequency Penalty', 'description': 'Penalize tokens based on how much they have already appeared in the text. Positive values encourage the model to generate new tokens and negative values encourage the model to repeat tokens. Available for models from LLM Engine, and OpenAI'}, 'presence_penalty': {'type': 'number', 'title': 'Presence Penalty', 'description': 'Penalize tokens based on if they have already appeared in the text. Positive values encourage the model to generate new tokens and negative values encourage the model to repeat tokens. Available for models from LLM Engine, and OpenAI.'}}, 'type': 'object', 'title': 'ModelParameters'}], 'title': 'Model Parameters', 'description': \"Configuration parameters for the agent model, such as temperature, max_tokens, and stop_sequences.\\n\\nIf not specified, the default value are:\\n- temperature: 0.2\\n- max_tokens: None (limited by the model's max tokens)\\n- stop_sequences: None\", 'default': {'temperature': 0.2}}, 'instructions': {'type': 'string', 'title': 'Instructions', 'description': 'The initial instructions to provide to the agent.\\n\\nUse this to guide the agent to act in more specific ways. For example, if you have specific rules you want to restrict the agent to follow you can specify them here. For example, if I want the agent to always use certain tools before others, I can write that rule in these instructions.\\n\\nGood prompt engineering is crucial to getting performant results from the agent. If you are having trouble getting the agent to perform well, try writing more specific instructions here before trying more expensive techniques such as swapping in other models or finetuning the underlying LLM.', 'default': \"You are an AI assistant that helps users with their questions. You can answer questions directly or acquire information from any of the attached tools to assist you. Always answer the user's most recent query to the best of your knowledge.\\n\\nWhen asked about what tools are available, you must list each attached tool's name and description. When asked about what you can do, mention that in addition to your normal capabilities, you can also use the attached tools by listing their names and descriptions. You cannot use any other tools other than the ones provided to you explicitly.\"}}, 'type': 'object', 'required': ['model', 'tools', 'messages'], 'title': 'ExecuteAgentRequest'}\n",
      "{'properties': {'account_id': {'type': 'string', 'title': 'Account Id', 'description': 'The account ID to use for usage tracking. This will be gradually enforced.'}, 'model': {'anyOf': [{'type': 'string', 'enum': ['gpt-4', 'gpt-4-0613', 'gpt-4-32k', 'gpt-4-32k-0613', 'gpt-4-vision-preview', 'gpt-4o', 'gpt-3.5-turbo', 'gpt-3.5-turbo-0613', 'gpt-3.5-turbo-16k', 'gpt-3.5-turbo-16k-0613', 'gemini-pro', 'gemini-1.5-pro-preview-0409', 'gemini-1.5-pro-preview-0514', 'text-davinci-003', 'text-davinci-002', 'text-curie-001', 'text-babbage-001', 'text-ada-001', 'claude-instant-1', 'claude-instant-1.1', 'claude-2', 'claude-2.0', 'llama-7b', 'llama-2-7b', 'llama-2-7b-chat', 'llama-2-13b', 'llama-2-13b-chat', 'llama-2-70b', 'llama-2-70b-chat', 'llama-3-8b', 'llama-3-8b-instruct', 'llama-3-70b-instruct', 'Meta-Llama-3-8B-Instruct-RMU', 'falcon-7b', 'falcon-7b-instruct', 'falcon-40b', 'falcon-40b-instruct', 'mpt-7b', 'mpt-7b-instruct', 'flan-t5-xxl', 'mistral-7b', 'mistral-7b-instruct', 'mixtral-8x7b', 'mixtral-8x7b-instruct', 'mixtral-8x22b-instruct', 'llm-jp-13b-instruct-full', 'llm-jp-13b-instruct-full-dolly', 'zephyr-7b-alpha', 'zephyr-7b-beta', 'codellama-7b', 'codellama-7b-instruct', 'codellama-13b', 'codellama-13b-instruct', 'codellama-34b', 'codellama-34b-instruct']}, {'type': 'string'}], 'title': 'Model', 'description': 'The ID of the model to use for completions.\\n\\nUsers have two options:\\n- Option 1: Use one of the supported models from the dropdown.\\n- Option 2: Enter the ID of a custom model.\\n\\nNote: For custom models we currently only support models finetuned using using the Scale-hosted LLM-Engine API.'}, 'prompt': {'type': 'string', 'title': 'Prompt', 'description': 'Prompt for which to generate the completion.\\n\\nGood prompt engineering is crucial to getting performant results from the model. If you are having trouble getting the model to perform well, try writing a more specific prompt here before trying more expensive techniques such as swapping in other models or finetuning the underlying LLM.'}, 'images': {'items': {'properties': {'image_url': {'type': 'string', 'title': 'Image Url', 'description': 'Image URL to run image completion on.'}, 'detail': {'type': 'string', 'title': 'Detail', 'description': 'Detail to run image completion with. Defaults to auto', 'default': 'auto'}}, 'type': 'object', 'required': ['image_url'], 'title': 'ImageCompletionRequests'}, 'type': 'array', 'title': 'Images', 'description': 'List of image urls to be used for image based completions. Leave empty for text based completions.'}, 'model_parameters': {'allOf': [{'properties': {'temperature': {'type': 'number', 'maximum': 1.0, 'minimum': 0.0, 'title': 'Temperature', 'description': 'What sampling temperature to use, between [0, 1]. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. Setting temperature=0.0 will enable fully deterministic (greedy) sampling.', 'default': 0.2}, 'stop_sequences': {'items': {'type': 'string'}, 'type': 'array', 'maxItems': 4, 'title': 'Stop Sequences', 'description': 'List of up to 4 sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence.'}, 'max_tokens': {'type': 'integer', 'title': 'Max Tokens', 'description': \"The maximum number of tokens to generate in the completion. The token count of your prompt plus max_tokens cannot exceed the model's context length. If not, specified, max_tokens will be determined based on the model used: \\n| Model API family | Model API default | EGP applied default |\\n| --- | --- | --- |\\n| OpenAI Completions | [`16`](https://platform.openai.com/docs/api-reference/completions/create#max_tokens) | `context window - prompt size` |\\n| OpenAI Chat Completions | [`context window - prompt size`](https://platform.openai.com/docs/api-reference/chat/create#max_tokens) | `context window - prompt size` |\\n| LLM Engine | [`max_new_tokens`](https://github.com/scaleapi/launch-python-client/blob/207adced1c88c1c2907266fa9dd1f1ff3ec0ea5b/launch/client.py#L2910) parameter is required | `100` |\\n| Anthropic Claude 2 | [`max_tokens_to_sample`](https://docs.anthropic.com/claude/reference/complete_post) parameter is required | `10000` |\\n\"}, 'topP': {'type': 'number', 'title': 'Topp', 'description': 'The cumulative probability cutoff for token selection. Lower values mean sampling from a smaller, more top-weighted nucleus. Available for models from Anthropic, Google, Mistral, LLM Engine, and OpenAI.'}, 'topK': {'type': 'integer', 'title': 'Topk', 'description': 'Sample from the k most likely next tokens at each step. Lower k focuses on higher probability tokens. Available for models from Anthropic, Google, and LLM Engine.'}, 'frequency_penalty': {'type': 'number', 'title': 'Frequency Penalty', 'description': 'Penalize tokens based on how much they have already appeared in the text. Positive values encourage the model to generate new tokens and negative values encourage the model to repeat tokens. Available for models from LLM Engine, and OpenAI'}, 'presence_penalty': {'type': 'number', 'title': 'Presence Penalty', 'description': 'Penalize tokens based on if they have already appeared in the text. Positive values encourage the model to generate new tokens and negative values encourage the model to repeat tokens. Available for models from LLM Engine, and OpenAI.'}}, 'type': 'object', 'title': 'ModelParameters'}], 'title': 'Model Parameters', 'description': \"Configuration parameters for the completion model, such as temperature, max_tokens, and stop_sequences.\\n\\nIf not specified, the default value are:\\n- temperature: 0.2\\n- max_tokens: None (limited by the model's max tokens)\\n- stop_sequences: None\", 'default': {'temperature': 0.2}}, 'stream': {'type': 'boolean', 'title': 'Stream', 'description': 'Whether or not to stream the response.\\n\\nSetting this to True will stream the completion in real-time.', 'default': False}}, 'type': 'object', 'required': ['model', 'prompt'], 'title': 'CreateCompletionRequest'}\n",
      "{'properties': {'model': {'type': 'string', 'enum': ['gpt-4', 'gpt-4-0613', 'gpt-4-32k', 'gpt-4-32k-0613', 'gpt-4o', 'gpt-3.5-turbo', 'gpt-3.5-turbo-0613', 'gpt-3.5-turbo-16k', 'gpt-3.5-turbo-16k-0613', 'llama-2-7b-chat', 'llama-2-13b-chat', 'llama-2-70b-chat', 'llama-3-70b-instruct', 'Meta-Llama-3-8B-Instruct-RMU', 'mixtral-8x7b-instruct', 'mixtral-8x22b-instruct', 'claude-3-opus-20240229', 'claude-3-sonnet-20240229', 'claude-3-haiku-20240307', 'claude-3-5-sonnet-20240620', 'mistral-large-latest'], 'title': 'Model', 'description': 'The ID of the model to use for chat completions. We only support the models listed here so far.'}, 'memory_strategy': {'allOf': [{'properties': {'name': {'type': 'string', 'enum': ['last_k'], 'const': 'last_k', 'title': 'Name', 'description': \"Name of the memory strategy. Must be `last_k`.\\n\\nThis strategy truncates the message history to the last `k` messages. It is the simplest way to prevent the model's context limit from being exceeded. However, this strategy only allows the model to have short term memory. For longer term memory, please use one of the other strategies.\", 'default': 'last_k'}, 'params': {'allOf': [{'properties': {'k': {'type': 'integer', 'minimum': 1.0, 'title': 'K', 'description': 'The maximum number of previous messages to remember.'}}, 'type': 'object', 'required': ['k'], 'title': 'LastKMemoryStrategyParams'}], 'title': 'Params', 'description': 'Configuration parameters for the memory strategy.'}}, 'type': 'object', 'required': ['params'], 'title': 'Last K Memory Strategy'}], 'title': 'Memory Strategy', 'description': \"The memory strategy to use for the agent. A memory strategy is a way to prevent the underlying LLM's context limit from being exceeded. Each memory strategy uses a different technique to condense the input message list into a smaller payload for the underlying LLM.\\n\\nWe only support the Last K memory strategy right now, but will be adding new strategies soon.\"}, 'messages': {'items': {'oneOf': [{'properties': {'role': {'type': 'string', 'enum': ['user'], 'const': 'user', 'title': 'Role', 'description': \"The role of the message. Must be set to 'user'.\\n\\nA user message is a message from the user to the AI. This should be the message used to send end user input to the AI.\", 'default': 'user'}, 'content': {'type': 'string', 'title': 'Content', 'description': 'Text input from the user'}}, 'type': 'object', 'required': ['content'], 'title': 'User Message'}, {'properties': {'role': {'type': 'string', 'enum': ['assistant'], 'const': 'assistant', 'title': 'Role', 'description': \"The role of the message. Must be set to 'assistant'.\\n\\nAn assistant message is a message from the AI to the client. It is different from an agent message in that it cannot contain a tool request. It is simply a direct response from the AI to the client.\", 'default': 'assistant'}, 'content': {'type': 'string', 'title': 'Content', 'description': 'Text response from the assistant'}}, 'type': 'object', 'required': ['content'], 'title': 'Assistant Message'}, {'properties': {'role': {'type': 'string', 'enum': ['system'], 'const': 'system', 'title': 'Role', 'description': \"The role of the message. Must be set to 'system'.\\n\\nA system message is different from other messages in that it does not originate from a party engaged in a user/AI conversation. Instead, it is a message that is injected by either the application or system to guide the conversation. For example, a system message may be used as initial instructions for an AI entity or to tell the AI that it did not do something correctly.\", 'default': 'system'}, 'content': {'type': 'string', 'title': 'Content', 'description': 'Text input from the system.'}}, 'type': 'object', 'required': ['content'], 'title': 'System Message'}], 'title': 'ChatMessage', 'discriminator': {'propertyName': 'role', 'mapping': {'user': '#/components/schemas/egp_api_backend__server__api__models__egp_models__UserMessage', 'assistant': '#/components/schemas/egp_api_backend__server__api__models__egp_models__AssistantMessage', 'system': '#/components/schemas/egp_api_backend__server__api__models__egp_models__SystemMessage'}}}, 'type': 'array', 'title': 'Messages', 'description': 'The list of messages in the conversation.\\n\\nExpand each message type to see how it works and when to use it. Most conversations should begin with a single `user` message.'}, 'model_parameters': {'allOf': [{'properties': {'temperature': {'type': 'number', 'maximum': 1.0, 'minimum': 0.0, 'title': 'Temperature', 'description': 'What sampling temperature to use, between [0, 1]. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. Setting temperature=0.0 will enable fully deterministic (greedy) sampling.', 'default': 0.2}, 'stop_sequences': {'items': {'type': 'string'}, 'type': 'array', 'maxItems': 4, 'title': 'Stop Sequences', 'description': 'List of up to 4 sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence.'}, 'max_tokens': {'type': 'integer', 'title': 'Max Tokens', 'description': \"The maximum number of tokens to generate in the completion. The token count of your prompt plus max_tokens cannot exceed the model's context length. If not, specified, max_tokens will be determined based on the model used: \\n| Model API family | Model API default | EGP applied default |\\n| --- | --- | --- |\\n| OpenAI Completions | [`16`](https://platform.openai.com/docs/api-reference/completions/create#max_tokens) | `context window - prompt size` |\\n| OpenAI Chat Completions | [`context window - prompt size`](https://platform.openai.com/docs/api-reference/chat/create#max_tokens) | `context window - prompt size` |\\n| LLM Engine | [`max_new_tokens`](https://github.com/scaleapi/launch-python-client/blob/207adced1c88c1c2907266fa9dd1f1ff3ec0ea5b/launch/client.py#L2910) parameter is required | `100` |\\n| Anthropic Claude 2 | [`max_tokens_to_sample`](https://docs.anthropic.com/claude/reference/complete_post) parameter is required | `10000` |\\n\"}, 'topP': {'type': 'number', 'title': 'Topp', 'description': 'The cumulative probability cutoff for token selection. Lower values mean sampling from a smaller, more top-weighted nucleus. Available for models from Anthropic, Google, Mistral, LLM Engine, and OpenAI.'}, 'topK': {'type': 'integer', 'title': 'Topk', 'description': 'Sample from the k most likely next tokens at each step. Lower k focuses on higher probability tokens. Available for models from Anthropic, Google, and LLM Engine.'}, 'frequency_penalty': {'type': 'number', 'title': 'Frequency Penalty', 'description': 'Penalize tokens based on how much they have already appeared in the text. Positive values encourage the model to generate new tokens and negative values encourage the model to repeat tokens. Available for models from LLM Engine, and OpenAI'}, 'presence_penalty': {'type': 'number', 'title': 'Presence Penalty', 'description': 'Penalize tokens based on if they have already appeared in the text. Positive values encourage the model to generate new tokens and negative values encourage the model to repeat tokens. Available for models from LLM Engine, and OpenAI.'}}, 'type': 'object', 'title': 'ModelParameters'}], 'title': 'Model Parameters', 'description': \"Configuration parameters for the chat completion model, such as temperature, max_tokens, and stop_sequences.\\n\\nIf not specified, the default value are:\\n- temperature: 0.2\\n- max_tokens: None (limited by the model's max tokens)\\n- stop_sequences: None\", 'default': {'temperature': 0.2}}, 'instructions': {'type': 'string', 'title': 'Instructions', 'description': 'The initial instructions to provide to the chat completion model.\\n\\nUse this to guide the model to act in more specific ways. For example, if you have specific rules you want to restrict the model to follow you can specify them here.\\n\\nGood prompt engineering is crucial to getting performant results from the model. If you are having trouble getting the model to perform well, try writing more specific instructions here before trying more expensive techniques such as swapping in other models or finetuning the underlying LLM.', 'default': 'You are an AI assistant that helps users with their questions by chatting back and forth with them. When asked a question, you should answer it as best as you can with the information you have. If you need more information, you can ask the user for it.'}, 'chat_template': {'type': 'string', 'title': 'Chat Template', 'description': \"Currently only supported for LLM-Engine models. A Jinja template string that defines how the chat completion API formats the string prompt. For Llama models, the template must take in at most a `messages` object, `bos_token` string, and `eos_token` string. The `messages` object is a list of dictionaries, each with keys `role` and `content`. For Mixtral models, the template must take in at most a `messages` object and `eos_token` string. The `messages` object looks identical to the Llama model's `messages` object, but the template can assume the `role` key takes on the values `user` or `assistant`, or `system` for the first message. The chat template either needs to handle this system message (which gets set via the `instructions` field or by the messages), or the `instructions` field must be set to `null` and the `messages` object must not contain any system messages.See the default chat template present in the Llama and Mixtral tokenizers for examples.\"}, 'stream': {'type': 'boolean', 'title': 'Stream', 'description': 'Whether or not to stream the response.\\n\\nSetting this to True will stream the completion in real-time.', 'default': False}}, 'type': 'object', 'required': ['model', 'messages'], 'title': 'CreateChatCompletionRequest'}\n",
      "{'properties': {'model_request_parameters': {'properties': {'bindings': {'additionalProperties': {'anyOf': [{'type': 'string'}, {'type': 'integer'}, {'type': 'number'}, {'type': 'boolean'}]}, 'type': 'object', 'title': 'Bindings'}}, 'additionalProperties': False, 'type': 'object', 'required': ['bindings'], 'title': 'ParameterBindings'}, 'texts': {'items': {'type': 'string'}, 'type': 'array', 'title': 'Texts'}}, 'additionalProperties': False, 'type': 'object', 'required': ['texts'], 'title': 'EmbeddingRequest'}\n",
      "{'properties': {'model_request_parameters': {'properties': {'bindings': {'additionalProperties': {'anyOf': [{'type': 'string'}, {'type': 'integer'}, {'type': 'number'}, {'type': 'boolean'}]}, 'type': 'object', 'title': 'Bindings'}}, 'additionalProperties': False, 'type': 'object', 'required': ['bindings'], 'title': 'ParameterBindings'}, 'query': {'type': 'string', 'title': 'Query'}, 'chunks': {'items': {'type': 'string'}, 'type': 'array', 'title': 'Chunks'}}, 'additionalProperties': False, 'type': 'object', 'required': ['query', 'chunks'], 'title': 'RerankingRequest'}\n",
      "{'properties': {'model_request_parameters': {'properties': {'bindings': {'additionalProperties': {'anyOf': [{'type': 'string'}, {'type': 'integer'}, {'type': 'number'}, {'type': 'boolean'}]}, 'type': 'object', 'title': 'Bindings'}}, 'additionalProperties': False, 'type': 'object', 'required': ['bindings'], 'title': 'ParameterBindings'}, 'temperature': {'type': 'number', 'maximum': 1.0, 'minimum': 0.0, 'title': 'Temperature', 'description': 'What sampling temperature to use, between [0, 1]. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. Setting temperature=0.0 will enable fully deterministic (greedy) sampling.', 'default': 0.2}, 'stop_sequences': {'items': {'type': 'string'}, 'type': 'array', 'maxItems': 4, 'title': 'Stop Sequences', 'description': 'List of up to 4 sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence.'}, 'max_tokens': {'type': 'integer', 'title': 'Max Tokens', 'description': \"The maximum number of tokens to generate in the completion. The token count of your prompt plus max_tokens cannot exceed the model's context length. If not, specified, max_tokens will be determined based on the model used: \\n| Model API family | Model API default | EGP applied default |\\n| --- | --- | --- |\\n| OpenAI Completions | [`16`](https://platform.openai.com/docs/api-reference/completions/create#max_tokens) | `context window - prompt size` |\\n| OpenAI Chat Completions | [`context window - prompt size`](https://platform.openai.com/docs/api-reference/chat/create#max_tokens) | `context window - prompt size` |\\n| LLM Engine | [`max_new_tokens`](https://github.com/scaleapi/launch-python-client/blob/207adced1c88c1c2907266fa9dd1f1ff3ec0ea5b/launch/client.py#L2910) parameter is required | `100` |\\n| Anthropic Claude 2 | [`max_tokens_to_sample`](https://docs.anthropic.com/claude/reference/complete_post) parameter is required | `10000` |\\n\"}, 'top_p': {'type': 'number', 'title': 'Top P', 'description': 'The cumulative probability cutoff for token selection. Lower values mean sampling from a smaller, more top-weighted nucleus. Available for models provided by Google, LLM Engine, and OpenAI.'}, 'top_k': {'type': 'number', 'title': 'Top K', 'description': 'Sample from the k most likely next tokens at each step. Lower k focuses on higher probability tokens. Available for models provided by Google and LLM Engine.'}, 'frequency_penalty': {'type': 'number', 'title': 'Frequency Penalty', 'description': 'Penalize tokens based on how much they have already appeared in the text. Positive values encourage the model to generate new tokens and negative values encourage the model to repeat tokens. Available for models provided by LLM Engine and OpenAI.'}, 'presence_penalty': {'type': 'number', 'title': 'Presence Penalty', 'description': 'Penalize tokens based on if they have already appeared in the text. Positive values encourage the model to generate new tokens and negative values encourage the model to repeat tokens. Available for models provided by LLM Engine and OpenAI.'}, 'prompt': {'type': 'string', 'title': 'Prompt'}}, 'additionalProperties': False, 'type': 'object', 'required': ['prompt'], 'title': 'CompletionRequestV2'}\n",
      "{'properties': {'model_request_parameters': {'properties': {'bindings': {'additionalProperties': {'anyOf': [{'type': 'string'}, {'type': 'integer'}, {'type': 'number'}, {'type': 'boolean'}]}, 'type': 'object', 'title': 'Bindings'}}, 'additionalProperties': False, 'type': 'object', 'required': ['bindings'], 'title': 'ParameterBindings'}, 'temperature': {'type': 'number', 'maximum': 1.0, 'minimum': 0.0, 'title': 'Temperature', 'description': 'What sampling temperature to use, between [0, 1]. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. Setting temperature=0.0 will enable fully deterministic (greedy) sampling.', 'default': 0.2}, 'stop_sequences': {'items': {'type': 'string'}, 'type': 'array', 'maxItems': 4, 'title': 'Stop Sequences', 'description': 'List of up to 4 sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence.'}, 'max_tokens': {'type': 'integer', 'title': 'Max Tokens', 'description': \"The maximum number of tokens to generate in the completion. The token count of your prompt plus max_tokens cannot exceed the model's context length. If not, specified, max_tokens will be determined based on the model used: \\n| Model API family | Model API default | EGP applied default |\\n| --- | --- | --- |\\n| OpenAI Completions | [`16`](https://platform.openai.com/docs/api-reference/completions/create#max_tokens) | `context window - prompt size` |\\n| OpenAI Chat Completions | [`context window - prompt size`](https://platform.openai.com/docs/api-reference/chat/create#max_tokens) | `context window - prompt size` |\\n| LLM Engine | [`max_new_tokens`](https://github.com/scaleapi/launch-python-client/blob/207adced1c88c1c2907266fa9dd1f1ff3ec0ea5b/launch/client.py#L2910) parameter is required | `100` |\\n| Anthropic Claude 2 | [`max_tokens_to_sample`](https://docs.anthropic.com/claude/reference/complete_post) parameter is required | `10000` |\\n\"}, 'top_p': {'type': 'number', 'title': 'Top P', 'description': 'The cumulative probability cutoff for token selection. Lower values mean sampling from a smaller, more top-weighted nucleus. Available for models provided by Google, LLM Engine, and OpenAI.'}, 'top_k': {'type': 'number', 'title': 'Top K', 'description': 'Sample from the k most likely next tokens at each step. Lower k focuses on higher probability tokens. Available for models provided by Google and LLM Engine.'}, 'frequency_penalty': {'type': 'number', 'title': 'Frequency Penalty', 'description': 'Penalize tokens based on how much they have already appeared in the text. Positive values encourage the model to generate new tokens and negative values encourage the model to repeat tokens. Available for models provided by LLM Engine and OpenAI.'}, 'presence_penalty': {'type': 'number', 'title': 'Presence Penalty', 'description': 'Penalize tokens based on if they have already appeared in the text. Positive values encourage the model to generate new tokens and negative values encourage the model to repeat tokens. Available for models provided by LLM Engine and OpenAI.'}, 'chat_history': {'items': {'oneOf': [{'properties': {'role': {'type': 'string', 'enum': ['user'], 'title': 'Role', 'default': 'user'}, 'content': {'type': 'string', 'title': 'Content'}}, 'type': 'object', 'required': ['content'], 'title': 'UserMessage'}, {'properties': {'role': {'type': 'string', 'enum': ['assistant'], 'title': 'Role', 'default': 'assistant'}, 'content': {'type': 'string', 'title': 'Content'}}, 'type': 'object', 'required': ['content'], 'title': 'AssistantMessage'}, {'properties': {'role': {'type': 'string', 'enum': ['system'], 'title': 'Role', 'default': 'system'}, 'content': {'type': 'string', 'title': 'Content'}}, 'type': 'object', 'required': ['content'], 'title': 'SystemMessage'}], 'title': 'ChatMessageV2', 'discriminator': {'propertyName': 'role', 'mapping': {'user': '#/components/schemas/egp_api_backend__server__internal__entities__UserMessage', 'assistant': '#/components/schemas/egp_api_backend__server__internal__entities__AssistantMessage', 'system': '#/components/schemas/egp_api_backend__server__internal__entities__SystemMessage'}}}, 'type': 'array', 'title': 'Chat History', 'description': \"Chat history entries with roles and messages. If there's no history, pass an empty list.\"}, 'prompt': {'type': 'string', 'title': 'Prompt', 'description': 'New user prompt. This will be sent to the model with a user role.'}}, 'additionalProperties': False, 'type': 'object', 'required': ['chat_history', 'prompt'], 'title': 'ChatCompletionRequest', 'description': 'Represents a chat completion request.\\n\\nAttributes:\\n    chat_history (List[Message]): Chat history'}\n",
      "{'properties': {'name': {'type': 'string', 'title': 'Name'}, 'model_creation_parameters': {'type': 'object', 'title': 'Model Creation Parameters'}, 'vendor_configuration': {'oneOf': [{'properties': {'min_workers': {'type': 'integer', 'title': 'Min Workers', 'default': 0}, 'max_workers': {'type': 'integer', 'title': 'Max Workers', 'default': 1}, 'per_worker': {'type': 'integer', 'title': 'Per Worker', 'description': 'The maximum number of concurrent requests that an individual worker can\\nservice. Launch automatically scales the number of workers for the endpoint so that\\neach worker is processing ``per_worker`` requests, subject to the limits defined by\\n``min_workers`` and ``max_workers``.\\n\\n- If the average number of concurrent requests per worker is lower than\\n``per_worker``, then the number of workers will be reduced. - Otherwise,\\nif the average number of concurrent requests per worker is higher than\\n``per_worker``, then the number of workers will be increased to meet the elevated\\ntraffic.\\n\\nHere is our recommendation for computing ``per_worker``:\\n\\n1. Compute ``min_workers`` and ``max_workers`` per your minimum and maximum\\nthroughput requirements. 2. Determine a value for the maximum number of\\nconcurrent requests in the workload. Divide this number by ``max_workers``. Doing\\nthis ensures that the number of workers will \"climb\" to ``max_workers``.', 'default': 10}, 'vendor': {'type': 'string', 'enum': ['LAUNCH'], 'title': 'Vendor', 'default': 'LAUNCH'}}, 'type': 'object', 'title': 'LaunchDeploymentVendorConfiguration'}, {'properties': {'cpus': {'type': 'integer', 'title': 'Cpus', 'default': 3}, 'memory': {'type': 'string', 'title': 'Memory', 'default': '8Gi'}, 'storage': {'type': 'string', 'title': 'Storage', 'default': '16Gi'}, 'gpus': {'type': 'integer', 'title': 'Gpus', 'default': 0}, 'gpu_type': {'type': 'string', 'enum': ['nvidia-tesla-t4', 'nvidia-ampere-a10', 'nvidia-ampere-a100', 'nvidia-ampere-a100e', 'nvidia-hopper-h100', 'nvidia-hopper-h100-1g20gb', 'nvidia-hopper-h100-3g40gb'], 'title': 'GPUType', 'description': 'An enumeration.'}, 'min_workers': {'type': 'integer', 'title': 'Min Workers', 'default': 0}, 'max_workers': {'type': 'integer', 'title': 'Max Workers', 'default': 1}, 'per_worker': {'type': 'integer', 'title': 'Per Worker', 'description': 'The maximum number of concurrent requests that an individual worker can\\nservice. Launch automatically scales the number of workers for the endpoint so that\\neach worker is processing ``per_worker`` requests, subject to the limits defined by\\n``min_workers`` and ``max_workers``.\\n\\n- If the average number of concurrent requests per worker is lower than\\n``per_worker``, then the number of workers will be reduced. - Otherwise,\\nif the average number of concurrent requests per worker is higher than\\n``per_worker``, then the number of workers will be increased to meet the elevated\\ntraffic.\\n\\nHere is our recommendation for computing ``per_worker``:\\n\\n1. Compute ``min_workers`` and ``max_workers`` per your minimum and maximum\\nthroughput requirements. 2. Determine a value for the maximum number of\\nconcurrent requests in the workload. Divide this number by ``max_workers``. Doing\\nthis ensures that the number of workers will \"climb\" to ``max_workers``.', 'default': 10}, 'vendor': {'type': 'string', 'enum': ['LLMENGINE'], 'title': 'Vendor', 'default': 'LLMENGINE'}, 'high_priority': {'type': 'boolean', 'title': 'High Priority', 'default': False}, 'num_shards': {'type': 'integer', 'title': 'Num Shards', 'default': 4}, 'checkpoint_path': {'type': 'string', 'title': 'Checkpoint Path'}, 'model_name': {'type': 'string', 'title': 'Model Name'}}, 'type': 'object', 'title': 'LLMEngineDeploymentVendorConfiguration'}], 'title': 'DeploymentVendorConfiguration', 'discriminator': {'propertyName': 'vendor', 'mapping': {'LAUNCH': '#/components/schemas/LaunchDeploymentVendorConfiguration', 'LLMENGINE': '#/components/schemas/LLMEngineDeploymentVendorConfiguration'}}}, 'deployment_metadata': {'type': 'object', 'title': 'Deployment Metadata'}, 'account_id': {'type': 'string', 'title': 'Account Id', 'description': 'The ID of the account that owns the given entity.', 'optional_in_request': True, 'can_patch': False}}, 'type': 'object', 'required': ['name'], 'title': 'ModelDeploymentRequest'}\n",
      "{'properties': {'account_name': {'type': 'string', 'title': 'Account Name', 'description': 'The name of the account. This will be displayed in the Scale GenAI Platform UI.'}}, 'type': 'object', 'required': ['account_name'], 'title': 'CreateAccountRequest'}\n",
      "{'properties': {'evaluation_type': {'allOf': [{'type': 'string', 'enum': ['studio', 'llm_auto', 'human', 'llm_benchmark'], 'title': 'EvaluationConfigORMEvaluationTypeEnum', 'description': 'An enumeration.'}], 'description': 'Evaluation type'}, 'question_set_id': {'type': 'string', 'title': 'Question Set Id'}, 'studio_project_id': {'type': 'string', 'title': 'Studio Project Id'}, 'account_id': {'type': 'string', 'title': 'Account Id', 'description': 'The ID of the account that owns the given entity.', 'can_patch': False}}, 'type': 'object', 'required': ['evaluation_type', 'question_set_id', 'account_id'], 'title': 'EvaluationConfigRequest'}\n",
      "{'oneOf': [{'properties': {'type': {'type': 'string', 'enum': ['manual'], 'const': 'manual', 'title': 'Type', 'description': 'Manually or automatically generated dataset', 'default': 'manual'}, 'name': {'type': 'string', 'title': 'Name', 'description': 'The name of the dataset'}, 'schema_type': {'allOf': [{'type': 'string', 'enum': ['GENERATION'], 'title': 'EvaluationDatasetORMSchemaTypeEnum', 'description': 'An enumeration.'}], 'description': 'The schema type of the dataset, currently only GENERATION is supported'}, 'account_id': {'type': 'string', 'title': 'Account Id', 'description': 'The ID of the account that owns the given entity.', 'can_patch': False}}, 'type': 'object', 'required': ['name', 'schema_type', 'account_id'], 'title': 'ManualEvaluationDatasetRequest'}, {'properties': {'type': {'type': 'string', 'enum': ['autogenerated'], 'const': 'autogenerated', 'title': 'Type', 'description': 'Manually or automatically generated dataset', 'default': 'autogenerated'}, 'name': {'type': 'string', 'title': 'Name', 'description': 'The name of the dataset'}, 'schema_type': {'allOf': [{'type': 'string', 'enum': ['GENERATION'], 'title': 'EvaluationDatasetORMSchemaTypeEnum', 'description': 'An enumeration.'}], 'description': 'The schema type of the dataset, currently only GENERATION is supported'}, 'knowledge_base_id': {'type': 'string', 'title': 'Knowledge Base Id', 'description': 'ID of the knowledge base to generate the evaluation dataset from.'}, 'account_id': {'type': 'string', 'title': 'Account Id', 'description': 'The ID of the account that owns the given entity.', 'can_patch': False}}, 'type': 'object', 'required': ['name', 'schema_type', 'knowledge_base_id', 'account_id'], 'title': 'AutoGeneratedEvaluationDatasetRequest'}], 'title': 'CreateEvaluationDatasetRequest', 'discriminator': {'propertyName': 'type', 'mapping': {'manual': '#/components/schemas/ManualEvaluationDatasetRequest', 'autogenerated': '#/components/schemas/AutoGeneratedEvaluationDatasetRequest'}}}\n",
      "{'properties': {'account_id': {'type': 'string', 'title': 'Account Id', 'description': 'The ID of the account that owns the given entity.', 'optional_in_request': True, 'can_patch': False}}, 'type': 'object', 'title': 'EvaluationDatasetVersionRequest'}\n",
      "{'properties': {'schema_type': {'allOf': [{'type': 'string', 'enum': ['GENERATION'], 'title': 'EvaluationDatasetORMSchemaTypeEnum', 'description': 'An enumeration.'}], 'description': 'The schema type of the dataset, currently only GENERATION is supported'}, 'test_case_data': {'type': 'object', 'title': 'Test Case Data', 'description': 'The data for the test case in a format matching the provided schema_type'}, 'chat_history': {'type': 'object', 'title': 'Chat History', 'description': 'Used for tracking previous chat interactions for multi-chat test cases'}, 'test_case_metadata': {'type': 'object', 'title': 'Test Case Metadata', 'description': 'Metadata for the test case'}, 'account_id': {'type': 'string', 'title': 'Account Id', 'description': 'The ID of the account that owns the given entity.', 'optional_in_request': True, 'can_patch': False}}, 'type': 'object', 'required': ['schema_type', 'test_case_data'], 'title': 'TestCaseVersionRequest'}\n",
      "{'items': {'properties': {'schema_type': {'allOf': [{'type': 'string', 'enum': ['GENERATION'], 'title': 'EvaluationDatasetORMSchemaTypeEnum', 'description': 'An enumeration.'}], 'description': 'The schema type of the dataset, currently only GENERATION is supported'}, 'test_case_data': {'type': 'object', 'title': 'Test Case Data', 'description': 'The data for the test case in a format matching the provided schema_type'}, 'chat_history': {'type': 'object', 'title': 'Chat History', 'description': 'Used for tracking previous chat interactions for multi-chat test cases'}, 'test_case_metadata': {'type': 'object', 'title': 'Test Case Metadata', 'description': 'Metadata for the test case'}, 'account_id': {'type': 'string', 'title': 'Account Id', 'description': 'The ID of the account that owns the given entity.', 'optional_in_request': True, 'can_patch': False}}, 'type': 'object', 'required': ['schema_type', 'test_case_data'], 'title': 'TestCaseVersionRequest'}, 'type': 'array', 'title': 'Request'}\n",
      "{'properties': {'name': {'type': 'string', 'title': 'Name', 'description': 'The name of the Studio Project'}, 'description': {'type': 'string', 'title': 'Description', 'description': 'The description of the Studio Project'}, 'studio_api_key': {'type': 'string', 'title': 'Studio Api Key', 'description': 'Your API key for Studio, can be updated with the PATCH endpoint'}, 'account_id': {'type': 'string', 'title': 'Account Id', 'description': 'The ID of the account that owns the given entity.', 'can_patch': False}}, 'type': 'object', 'required': ['name', 'description', 'studio_api_key', 'account_id'], 'title': 'StudioProjectRequest'}\n",
      "{'properties': {'name': {'type': 'string', 'title': 'Name', 'description': 'The name of the Application Spec'}, 'description': {'type': 'string', 'title': 'Description', 'description': 'The description of the Application Spec'}, 'theme_id': {'type': 'string', 'title': 'Theme Id', 'can_patch': True}, 'run_online_evaluation': {'type': 'boolean', 'title': 'Run Online Evaluation', 'description': 'Whether the application spec should run online evaluation, default is `false`'}, 'account_id': {'type': 'string', 'title': 'Account Id', 'description': 'The ID of the account that owns the given entity.', 'can_patch': False}}, 'type': 'object', 'required': ['name', 'description', 'account_id'], 'title': 'ApplicationSpecRequest'}\n",
      "{'oneOf': [{'properties': {'name': {'type': 'string', 'title': 'Name'}, 'description': {'type': 'string', 'title': 'Description'}, 'application_spec_id': {'type': 'string', 'title': 'Application Spec Id'}, 'application_variant_id': {'type': 'string', 'title': 'Application Variant Id'}, 'tags': {'type': 'object', 'title': 'Tags'}, 'evaluation_config': {'type': 'object', 'title': 'Evaluation Config'}, 'evaluation_config_id': {'type': 'string', 'title': 'Evaluation Config Id', 'description': 'The ID of the associated evaluation config.'}, 'account_id': {'type': 'string', 'title': 'Account Id', 'description': 'The ID of the account that owns the given entity.', 'can_patch': False}, 'type': {'type': 'string', 'enum': ['builder'], 'const': 'builder', 'title': 'Type', 'description': 'create standalone evaluation or build evaluation which will auto generate test case results', 'default': 'builder'}, 'evaluation_dataset_id': {'type': 'string', 'title': 'Evaluation Dataset Id'}, 'evaluation_dataset_version': {'type': 'integer', 'title': 'Evaluation Dataset Version'}}, 'type': 'object', 'required': ['name', 'description', 'application_spec_id', 'application_variant_id', 'account_id', 'evaluation_dataset_id'], 'title': 'EvaluationBuilderRequest'}, {'properties': {'name': {'type': 'string', 'title': 'Name'}, 'description': {'type': 'string', 'title': 'Description'}, 'application_spec_id': {'type': 'string', 'title': 'Application Spec Id'}, 'application_variant_id': {'type': 'string', 'title': 'Application Variant Id'}, 'tags': {'type': 'object', 'title': 'Tags'}, 'evaluation_config': {'type': 'object', 'title': 'Evaluation Config'}, 'evaluation_config_id': {'type': 'string', 'title': 'Evaluation Config Id', 'description': 'The ID of the associated evaluation config.'}, 'account_id': {'type': 'string', 'title': 'Account Id', 'description': 'The ID of the account that owns the given entity.', 'can_patch': False}, 'type': {'type': 'string', 'enum': ['default'], 'const': 'default', 'title': 'Type', 'description': 'create standalone evaluation or build evaluation which will auto generate test case results', 'default': 'default'}}, 'type': 'object', 'required': ['name', 'description', 'application_spec_id', 'account_id'], 'title': 'DefaultEvaluationRequest'}], 'title': 'EvaluationRequestUnion', 'discriminator': {'propertyName': 'type', 'mapping': {'builder': '#/components/schemas/EvaluationBuilderRequest', 'default': '#/components/schemas/DefaultEvaluationRequest'}}}\n",
      "{'properties': {'audit_status': {'type': 'string', 'enum': ['UNAUDITED', 'FIXED', 'APPROVED'], 'title': 'AuditORMStatusEnum', 'description': 'An enumeration.'}, 'audit_required': {'type': 'boolean', 'title': 'Audit Required'}, 'audit_comment': {'type': 'string', 'title': 'Audit Comment'}, 'application_spec_id': {'type': 'string', 'title': 'Application Spec Id'}, 'evaluation_dataset_version_num': {'type': 'string', 'title': 'Evaluation Dataset Version Num'}, 'test_case_id': {'type': 'string', 'title': 'Test Case Id'}, 'test_case_evaluation_data': {'type': 'object', 'title': 'Test Case Evaluation Data'}, 'test_case_evaluation_data_schema': {'type': 'string', 'enum': ['GENERATION'], 'title': 'EvaluationDatasetORMSchemaTypeEnum', 'description': 'An enumeration.'}, 'result': {'type': 'object', 'title': 'Result'}, 'time_spent_labeling_s': {'type': 'integer', 'title': 'Time Spent Labeling S', 'description': 'The time spent labeling in seconds.'}, 'account_id': {'type': 'string', 'title': 'Account Id', 'description': 'The ID of the account that owns the given entity.', 'optional_in_request': True, 'can_patch': False}, 'annotated_by_user_id': {'type': 'string', 'title': 'Annotated By User Id', 'description': 'The user who annotated the task.'}}, 'type': 'object', 'required': ['application_spec_id', 'evaluation_dataset_version_num', 'test_case_id', 'test_case_evaluation_data', 'test_case_evaluation_data_schema'], 'title': 'TestCaseResultRequest'}\n",
      "{'items': {'properties': {'audit_status': {'type': 'string', 'enum': ['UNAUDITED', 'FIXED', 'APPROVED'], 'title': 'AuditORMStatusEnum', 'description': 'An enumeration.'}, 'audit_required': {'type': 'boolean', 'title': 'Audit Required'}, 'audit_comment': {'type': 'string', 'title': 'Audit Comment'}, 'application_spec_id': {'type': 'string', 'title': 'Application Spec Id'}, 'evaluation_dataset_version_num': {'type': 'string', 'title': 'Evaluation Dataset Version Num'}, 'test_case_id': {'type': 'string', 'title': 'Test Case Id'}, 'test_case_evaluation_data': {'type': 'object', 'title': 'Test Case Evaluation Data'}, 'test_case_evaluation_data_schema': {'type': 'string', 'enum': ['GENERATION'], 'title': 'EvaluationDatasetORMSchemaTypeEnum', 'description': 'An enumeration.'}, 'result': {'type': 'object', 'title': 'Result'}, 'time_spent_labeling_s': {'type': 'integer', 'title': 'Time Spent Labeling S', 'description': 'The time spent labeling in seconds.'}, 'account_id': {'type': 'string', 'title': 'Account Id', 'description': 'The ID of the account that owns the given entity.', 'optional_in_request': True, 'can_patch': False}, 'annotated_by_user_id': {'type': 'string', 'title': 'Annotated By User Id', 'description': 'The user who annotated the task.'}}, 'type': 'object', 'required': ['application_spec_id', 'evaluation_dataset_version_num', 'test_case_id', 'test_case_evaluation_data', 'test_case_evaluation_data_schema'], 'title': 'TestCaseResultRequest'}, 'type': 'array', 'title': 'Request'}\n",
      "{'properties': {'type': {'allOf': [{'type': 'string', 'enum': ['categorical', 'free_text'], 'title': 'QuestionORMTypeEnum', 'description': 'An enumeration.'}], 'description': 'The type of question'}, 'title': {'type': 'string', 'title': 'Title'}, 'prompt': {'type': 'string', 'title': 'Prompt'}, 'choices': {'items': {'type': 'object'}, 'type': 'array', 'title': 'Choices', 'description': 'List of choices for the question. Required for CATEGORICAL questions.'}, 'multi': {'type': 'boolean', 'title': 'Multi', 'description': 'Whether the question allows multiple answers.'}, 'dropdown': {'type': 'boolean', 'title': 'Dropdown', 'description': 'Whether the question is displayed as a dropdown in the UI.'}, 'required': {'type': 'boolean', 'title': 'Required', 'description': 'Whether the question is required.'}, 'conditions': {'items': {'type': 'object'}, 'type': 'array', 'title': 'Conditions', 'description': 'Conditions for the question to be shown.'}, 'account_id': {'type': 'string', 'title': 'Account Id', 'description': 'The ID of the account that owns the given entity.', 'can_patch': False}}, 'type': 'object', 'required': ['type', 'title', 'prompt', 'account_id'], 'title': 'QuestionRequest'}\n",
      "{'properties': {'name': {'type': 'string', 'title': 'Name'}, 'account_id': {'type': 'string', 'title': 'Account Id', 'description': 'The ID of the account that owns the given entity.', 'can_patch': False}, 'question_ids': {'items': {'type': 'string'}, 'type': 'array', 'title': 'Question Ids', 'description': 'IDs of questions in the question set'}}, 'type': 'object', 'required': ['name', 'account_id', 'question_ids'], 'title': 'QuestionSetRequest'}\n",
      "{'properties': {'name': {'type': 'string', 'title': 'Name'}, 'description': {'type': 'string', 'title': 'Description'}, 'data_source_config': {'allOf': [{'oneOf': [{'properties': {'source': {'type': 'string', 'enum': ['S3'], 'title': 'Source'}, 's3_bucket': {'type': 'string', 'title': 'S3 Bucket', 'description': 'Name of the S3 bucket where the data is stored.'}, 's3_prefix': {'type': 'string', 'title': 'S3 Prefix', 'description': 'Prefix of the S3 bucket where the data is stored. If not specified, the entire bucket will be used.', 'default': ''}, 'aws_region': {'type': 'string', 'title': 'Aws Region', 'description': 'AWS region where the S3 bucket is located.'}, 'aws_account_id': {'type': 'string', 'pattern': '^\\\\d{12}$', 'title': 'Aws Account Id', 'description': 'AWS account ID that owns the S3 bucket.'}}, 'type': 'object', 'required': ['source', 's3_bucket', 'aws_region', 'aws_account_id'], 'title': 'S3 DataSource Config'}, {'properties': {'source': {'type': 'string', 'enum': ['SharePoint'], 'title': 'Source'}, 'client_id': {'type': 'string', 'title': 'Client Id', 'description': 'Client ID associated with this SharePoint site'}, 'tenant_id': {'type': 'string', 'title': 'Tenant Id', 'description': 'Tenant ID that the SharePoint site is within'}, 'site_id': {'type': 'string', 'title': 'Site Id', 'description': 'Site ID for this SharePoint site, can be found at https://[hostname].sharepoint.com/sites/[site name]/_api/site/id'}, 'folder_path': {'type': 'string', 'title': 'Folder Path', 'description': \"Nested folder path to read files from the root of the site. Please omit the leading slash. Example: 'Documents/sub_directory'\", 'default': ''}, 'recursive': {'type': 'boolean', 'title': 'Recursive', 'description': 'Recurse through the folder contents, default is True.', 'default': True}}, 'type': 'object', 'required': ['source', 'client_id', 'tenant_id', 'site_id'], 'title': 'SharePoint DataSource Config'}, {'properties': {'source': {'type': 'string', 'enum': ['GoogleDrive'], 'title': 'Source'}, 'drive_id': {'type': 'string', 'title': 'Drive Id', 'description': 'ID associated with the Google Drive to retrieve contents from'}}, 'type': 'object', 'required': ['source', 'drive_id'], 'title': 'Google Drive DataSource Config'}, {'properties': {'source': {'type': 'string', 'enum': ['AzureBlobStorage'], 'title': 'Source'}, 'container_url': {'type': 'string', 'title': 'Container Url', 'description': \"The full URL of the container such as 'https://your-account-name.blob.core.windows.net/your-container-name'\"}}, 'type': 'object', 'required': ['source', 'container_url'], 'title': 'Azure Blob Storage DataSource Config'}, {'properties': {'source': {'type': 'string', 'enum': ['Confluence'], 'title': 'Source'}, 'space_key': {'type': 'string', 'title': 'Space Key', 'description': 'Confluence space key to retrieve contents from. See https://support.atlassian.com/confluence-cloud/docs/choose-a-space-key'}}, 'type': 'object', 'required': ['source', 'space_key'], 'title': 'Confluence DataSource Config'}, {'properties': {'source': {'type': 'string', 'enum': ['Slack'], 'title': 'Source'}, 'channel_id': {'type': 'string', 'title': 'Channel Id', 'description': \"Slack Channel or Conversation ID to retrieve history from. Open channel details and find the ID at bottom of 'About' section.\"}}, 'type': 'object', 'required': ['source', 'channel_id'], 'title': 'Slack DataSource Config'}], 'title': 'RemoteDataSourceConfig', 'discriminator': {'propertyName': 'source', 'mapping': {'S3': '#/components/schemas/S3DataSourceConfig', 'SharePoint': '#/components/schemas/SharePointDataSourceConfig', 'GoogleDrive': '#/components/schemas/GoogleDriveDataSourceConfig', 'AzureBlobStorage': '#/components/schemas/AzureBlobStorageDataSourceConfig', 'Confluence': '#/components/schemas/ConfluenceDataSourceConfig', 'Slack': '#/components/schemas/SlackDataSourceConfig'}}}], 'title': 'Data Source Config', 'can_patch': False}, 'data_source_auth_config': {'oneOf': [{'properties': {'encrypted': {'type': 'boolean', 'title': 'Encrypted', 'default': False}, 'source': {'type': 'string', 'enum': ['SharePoint'], 'title': 'Source'}, 'client_secret': {'type': 'string', 'title': 'Client Secret', 'description': 'Secret for the app registration associated with this SharePoint site'}}, 'type': 'object', 'required': ['source', 'client_secret'], 'title': 'SharePoint DataSource Auth Config'}, {'properties': {'encrypted': {'type': 'boolean', 'title': 'Encrypted', 'default': False}, 'source': {'type': 'string', 'enum': ['AzureBlobStorage'], 'title': 'Source'}, 'blob_sas_token': {'type': 'string', 'title': 'Blob Sas Token', 'description': 'Shared Access Signature token for the Azure Blob Storage container'}}, 'type': 'object', 'required': ['source', 'blob_sas_token'], 'title': 'Azure DataSource Auth Config'}, {'properties': {'encrypted': {'type': 'boolean', 'title': 'Encrypted', 'default': False}, 'source': {'type': 'string', 'enum': ['GoogleDrive'], 'title': 'Source'}, 'client_email': {'type': 'string', 'title': 'Client Email', 'description': 'Client email to use for google drive, set to override client email set in env vars'}, 'private_key': {'type': 'string', 'title': 'Private Key', 'description': 'Private key to use for google drive, set to override private key set in env vars'}, 'token_uri': {'type': 'string', 'title': 'Token Uri', 'description': 'Token uri to use for google drive, set to override token uri set in env vars'}, 'client_id': {'type': 'string', 'title': 'Client Id', 'description': 'Client id to use for google drive, set to override client id set in env vars'}}, 'type': 'object', 'required': ['source', 'client_email', 'private_key', 'token_uri', 'client_id'], 'title': 'Google Drive DataSource Auth Config'}, {'properties': {'encrypted': {'type': 'boolean', 'title': 'Encrypted', 'default': False}, 'source': {'type': 'string', 'enum': ['S3'], 'title': 'Source'}, 's3_role': {'type': 'string', 'title': 'S3 Role', 'description': 'Name of the role that a client will be initialized via AssumeRole of AWS sts'}, 'external_id': {'type': 'string', 'title': 'External Id', 'description': 'External ID defined by the customer for the IAM role'}}, 'type': 'object', 'required': ['source'], 'title': 'S3 DataSource Auth Config'}, {'properties': {'encrypted': {'type': 'boolean', 'title': 'Encrypted', 'default': False}, 'source': {'type': 'string', 'enum': ['Confluence'], 'title': 'Source'}, 'client_email': {'type': 'string', 'title': 'Client Email', 'description': 'Client email to use for Confluence, set to override client email set in env vars.'}, 'api_key': {'type': 'string', 'title': 'Api Key', 'description': 'API key to use for Confluence, set this to override api key configured in env vars.'}, 'atlassian_domain': {'type': 'string', 'title': 'Atlassian Domain', 'description': \"Your Confluence API server's full domain, set to override domain configured in env vars. E.g. 'https://[your-company].atlassian.net'\"}}, 'type': 'object', 'required': ['source', 'client_email', 'api_key', 'atlassian_domain'], 'title': 'Confluence DataSource Auth Config'}, {'properties': {'encrypted': {'type': 'boolean', 'title': 'Encrypted', 'default': False}, 'source': {'type': 'string', 'enum': ['Slack'], 'title': 'Source'}, 'bot_token': {'type': 'string', 'title': 'Bot Token', 'description': \"Your Slack app's Bot OAuth token. See https://api.slack.com/quickstart\"}}, 'type': 'object', 'required': ['source', 'bot_token'], 'title': 'Slack DataSource Auth Config'}], 'title': 'DataSourceAuthConfig', 'discriminator': {'propertyName': 'source', 'mapping': {'SharePoint': '#/components/schemas/SharePointDataSourceAuthConfig', 'AzureBlobStorage': '#/components/schemas/AzureBlobStorageDataSourceAuthConfig', 'GoogleDrive': '#/components/schemas/GoogleDriveDataSourceAuthConfig', 'S3': '#/components/schemas/S3DataSourceAuthConfig', 'Confluence': '#/components/schemas/ConfluenceDataSourceAuthConfig', 'Slack': '#/components/schemas/SlackDataSourceAuthConfig'}}}, 'account_id': {'type': 'string', 'title': 'Account Id', 'description': 'The ID of the account that owns the given entity.', 'can_patch': False}}, 'type': 'object', 'required': ['name', 'data_source_config', 'account_id'], 'title': 'KnowledgeBaseDataSourceRequest'}\n",
      "{'properties': {'knowledge_base_data_source_id': {'type': 'string', 'title': 'Knowledge Base Data Source Id', 'can_patch': False}, 'chunking_strategy_config': {'oneOf': [{'properties': {'strategy': {'type': 'string', 'enum': ['character'], 'title': 'Strategy'}, 'separator': {'type': 'string', 'title': 'Separator', 'description': 'Character designating breaks in input data. Text data will first be split into sections by this separator, then each section will be split into chunks of size `chunk_size`.', 'default': '\\n\\n'}, 'chunk_size': {'type': 'integer', 'minimum': 1.0, 'title': 'Chunk Size', 'description': 'Maximum number of characters in each chunk. If not specified, a chunk size of 1000 will be used.', 'default': 1000}, 'chunk_overlap': {'type': 'integer', 'minimum': 0.0, 'title': 'Chunk Overlap', 'description': \"Number of characters to overlap between chunks. If not specified, an overlap of 200 will be used. For example if the chunk size is 3 and the overlap size is 1, and the text to chunk is 'abcde', the chunks will be 'abc', 'cde'.\", 'default': 200}}, 'type': 'object', 'required': ['strategy'], 'title': 'CharacterChunkingStrategyConfig'}, {'properties': {'strategy': {'type': 'string', 'enum': ['token'], 'title': 'Strategy'}, 'separator': {'type': 'string', 'title': 'Separator', 'description': 'Character designating breaks in input data. Text data will first be split into sections by this separator, then each section will be split into chunks of size `chunk_size`.', 'default': '\\n\\n'}, 'target_chunk_size': {'type': 'integer', 'minimum': 1.0, 'title': 'Target Chunk Size', 'description': 'Target number of tokens in each chunk. If not specified, a target chunk size of 200 will be used.', 'default': 200}, 'max_chunk_size': {'type': 'integer', 'minimum': 1.0, 'title': 'Max Chunk Size', 'description': 'Maximum number of tokens in each chunk. If not specified, a maximum chunk size of 600 will be used.', 'default': 600}, 'chunk_overlap': {'type': 'integer', 'minimum': 0.0, 'title': 'Chunk Overlap', 'description': 'Number of tokens to overlap between chunks. If not specified, an overlap of 0 will be used. Not this if only followed approximately.', 'default': 0}}, 'type': 'object', 'required': ['strategy'], 'title': 'TokenChunkingStrategyConfig'}, {'properties': {'strategy': {'type': 'string', 'enum': ['custom'], 'title': 'Strategy'}, 'endpoint': {'type': 'string', 'title': 'Endpoint', 'description': 'Endpoint path to call for custom chunking'}, 'params': {'type': 'object', 'title': 'Params', 'description': 'Parameters that will be appended to the body of the request for the chunk.', 'default': {}}}, 'type': 'object', 'required': ['strategy', 'endpoint'], 'title': 'CustomChunkingStrategyConfig'}], 'title': 'ChunkingStrategyConfig', 'discriminator': {'propertyName': 'strategy', 'mapping': {'character': '#/components/schemas/CharacterChunkingStrategyConfig', 'token': '#/components/schemas/TokenChunkingStrategyConfig', 'custom': '#/components/schemas/CustomChunkingStrategyConfig'}}}, 'interval': {'type': 'number', 'format': 'time-delta', 'title': 'Interval'}, 'next_run_at': {'type': 'string', 'format': 'date-time', 'title': 'Next Run At'}, 'account_id': {'type': 'string', 'title': 'Account Id', 'description': 'The ID of the account that owns the given entity.', 'optional_in_request': True, 'can_patch': False}}, 'type': 'object', 'required': ['knowledge_base_data_source_id', 'chunking_strategy_config', 'interval'], 'title': 'KnowledgeBaseUploadScheduleRequest'}\n",
      "{'properties': {'schema_type': {'allOf': [{'type': 'string', 'enum': ['GENERATION'], 'title': 'EvaluationDatasetORMSchemaTypeEnum', 'description': 'An enumeration.'}], 'description': 'The schema type of the dataset, currently only GENERATION is supported'}, 'test_case_data': {'type': 'object', 'title': 'Test Case Data', 'description': 'The data for the test case in a format matching the provided schema_type'}, 'approved': {'type': 'boolean', 'title': 'Approved', 'description': 'Boolean to track whether or not the draft test case is approved'}, 'topic_str': {'type': 'string', 'title': 'Topic Str', 'can_patch': False}, 'account_id': {'type': 'string', 'title': 'Account Id', 'description': 'The ID of the account that owns the given entity.', 'can_patch': False}}, 'type': 'object', 'required': ['schema_type', 'test_case_data', 'approved', 'topic_str', 'account_id'], 'title': 'AutoGeneratedDraftTestCaseRequest'}\n",
      "{'properties': {'autogenerated_draft_test_cases': {'items': {'type': 'string'}, 'type': 'array', 'title': 'Autogenerated Draft Test Cases', 'description': 'Ids of auto generated draft test cases to be approved.'}}, 'type': 'object', 'required': ['autogenerated_draft_test_cases'], 'title': 'AutoGeneratedDraftTestCaseApproveBatchRequest'}\n",
      "{'properties': {'num_test_cases': {'type': 'integer', 'title': 'Num Test Cases', 'description': 'Number of test cases to generate for the evaluation dataset'}}, 'type': 'object', 'title': 'CreateEvaluationDatasetGenerationJobRequest'}\n",
      "{'properties': {'name': {'type': 'string', 'title': 'Name'}, 'model_vendor': {'type': 'string', 'enum': ['OPENAI', 'COHERE', 'GOOGLE', 'ANTHROPIC', 'LAUNCH', 'LLMENGINE', 'BEDROCK', 'OTHER'], 'title': 'ModelVendor', 'description': 'An enum representing the different types of model vendors supported.\\n\\nAttributes:\\n    OPENAI: Denotes that the model vendor is OpenAI.\\n    COHERE: Denotes that the model vendor is Cohere.\\n    GOOGLE: Denotes that the model vendor is Google.\\n    ANTHROPIC: Denotes that the model vendor is Anthropic.\\n    LLMENGINE: Denotes that the model vendor is LLM Engine.\\n    OTHER: Denotes that the model vendor is Other.'}, 'model_type': {'type': 'string', 'enum': ['COMPLETION', 'CHAT_COMPLETION', 'AGENT', 'EMBEDDING', 'RERANKING'], 'title': 'ModelType', 'description': 'An enum representing the different types of models supported.\\n\\nAttributes:\\n    COMPLETION: Denotes that the model type is completion.\\n    CHAT_COMPLETION: Denotes that the model type is chat completion.\\n    AGENT: Denotes that the model type is agent.\\n    EMBEDDING: Denotes that the model type is embedding.\\n    RERANKING: Denotes that the model type is reranking.'}, 'base_model_id': {'type': 'string', 'title': 'Base Model Id'}, 'base_model_metadata': {'properties': {'ui_model_section_type': {'type': 'string', 'enum': ['PARTNER', 'OPENSOURCE', 'CUSTOM'], 'title': 'UiModelSectionType', 'description': 'An enumeration.'}, 'model_developer': {'type': 'string', 'title': 'Model Developer'}, 'model_license_url': {'type': 'string', 'title': 'Model License Url'}, 'delivery_date': {'type': 'string', 'title': 'Delivery Date'}, 'modelDetails': {'properties': {'number_of_parameters': {'type': 'integer', 'title': 'Number Of Parameters'}, 'token_context_window': {'type': 'integer', 'title': 'Token Context Window'}, 'languages': {'type': 'integer', 'title': 'Languages'}, 'alignments': {'type': 'integer', 'title': 'Alignments'}}, 'type': 'object', 'title': 'BaseModelDetails'}}, 'type': 'object', 'title': 'BaseModelMetadata'}, 'model_creation_parameters': {'type': 'object', 'title': 'Model Creation Parameters'}, 'model_card': {'type': 'string', 'title': 'Model Card'}, 'training_data_card': {'type': 'string', 'title': 'Training Data Card'}, 'description': {'type': 'string', 'title': 'Description'}, 'model_template_id': {'type': 'string', 'title': 'Model Template Id'}, 'model_group_id': {'type': 'string', 'title': 'Model Group Id'}, 'account_id': {'type': 'string', 'title': 'Account Id', 'description': 'The ID of the account that owns the given entity.', 'can_patch': False}}, 'type': 'object', 'required': ['name', 'model_type', 'account_id'], 'title': 'ModelInstanceRequest'}\n",
      "{'properties': {'name': {'type': 'string', 'title': 'Name'}, 'description': {'type': 'string', 'title': 'Description'}, 'account_id': {'type': 'string', 'title': 'Account Id', 'description': 'The ID of the account that owns the given entity.', 'can_patch': False}}, 'type': 'object', 'required': ['name', 'account_id'], 'title': 'ModelGroupRequest'}\n",
      "{'properties': {'name': {'type': 'string', 'title': 'Name'}, 'endpoint_type': {'type': 'string', 'enum': ['SYNC', 'ASYNC', 'STREAMING', 'BATCH'], 'title': 'ModelEndpointType', 'description': 'An enum representing the different types of model endpoint types supported.\\n\\nAttributes:\\n    SYNC: Denotes that the model endpoint type is sync.\\n    ASYNC: Denotes that the model endpoint type is async.\\n    STREAMING: Denotes that the model endpoint type is streaming.\\n    BATCH: Denotes that the model endpoint type is batch.'}, 'model_type': {'type': 'string', 'enum': ['COMPLETION', 'CHAT_COMPLETION', 'AGENT', 'EMBEDDING', 'RERANKING'], 'title': 'ModelType', 'description': 'An enum representing the different types of models supported.\\n\\nAttributes:\\n    COMPLETION: Denotes that the model type is completion.\\n    CHAT_COMPLETION: Denotes that the model type is chat completion.\\n    AGENT: Denotes that the model type is agent.\\n    EMBEDDING: Denotes that the model type is embedding.\\n    RERANKING: Denotes that the model type is reranking.'}, 'vendor_configuration': {'properties': {'vendor': {'type': 'string', 'enum': ['LAUNCH'], 'title': 'Vendor', 'default': 'LAUNCH'}, 'bundle_config': {'properties': {'registry': {'type': 'string', 'title': 'Registry'}, 'image': {'type': 'string', 'title': 'Image'}, 'tag': {'type': 'string', 'title': 'Tag'}, 'command': {'items': {'type': 'string'}, 'type': 'array', 'title': 'Command'}, 'env': {'additionalProperties': {'type': 'string'}, 'type': 'object', 'title': 'Env'}, 'streaming_command': {'items': {'type': 'string'}, 'type': 'array', 'title': 'Streaming Command'}, 'readiness_initial_delay_seconds': {'type': 'integer', 'title': 'Readiness Initial Delay Seconds', 'default': 120}, 'healthcheck_route': {'type': 'string', 'title': 'Healthcheck Route', 'default': '/readyz'}, 'predict_route': {'type': 'string', 'title': 'Predict Route', 'default': '/predict'}, 'streaming_predict_route': {'type': 'string', 'title': 'Streaming Predict Route', 'default': '/generate_streaming'}}, 'type': 'object', 'required': ['registry', 'image', 'tag'], 'title': 'ModelBundleConfiguration'}, 'endpoint_config': {'properties': {'cpus': {'type': 'integer', 'title': 'Cpus', 'default': 3}, 'memory': {'type': 'string', 'title': 'Memory', 'default': '8Gi'}, 'storage': {'type': 'string', 'title': 'Storage', 'default': '16Gi'}, 'gpus': {'type': 'integer', 'title': 'Gpus', 'default': 0}, 'gpu_type': {'type': 'string', 'enum': ['nvidia-tesla-t4', 'nvidia-ampere-a10', 'nvidia-ampere-a100', 'nvidia-ampere-a100e', 'nvidia-hopper-h100', 'nvidia-hopper-h100-1g20gb', 'nvidia-hopper-h100-3g40gb'], 'title': 'GPUType', 'description': 'An enumeration.'}, 'min_workers': {'type': 'integer', 'title': 'Min Workers', 'default': 0}, 'max_workers': {'type': 'integer', 'title': 'Max Workers', 'default': 1}, 'per_worker': {'type': 'integer', 'title': 'Per Worker', 'description': 'The maximum number of concurrent requests that an individual worker can\\nservice. Launch automatically scales the number of workers for the endpoint so that\\neach worker is processing ``per_worker`` requests, subject to the limits defined by\\n``min_workers`` and ``max_workers``.\\n\\n- If the average number of concurrent requests per worker is lower than\\n``per_worker``, then the number of workers will be reduced. - Otherwise,\\nif the average number of concurrent requests per worker is higher than\\n``per_worker``, then the number of workers will be increased to meet the elevated\\ntraffic.\\n\\nHere is our recommendation for computing ``per_worker``:\\n\\n1. Compute ``min_workers`` and ``max_workers`` per your minimum and maximum\\nthroughput requirements. 2. Determine a value for the maximum number of\\nconcurrent requests in the workload. Divide this number by ``max_workers``. Doing\\nthis ensures that the number of workers will \"climb\" to ``max_workers``.', 'default': 10}, 'endpoint_type': {'allOf': [{'type': 'string', 'enum': ['SYNC', 'ASYNC', 'STREAMING', 'BATCH'], 'title': 'ModelEndpointType', 'description': 'An enum representing the different types of model endpoint types supported.\\n\\nAttributes:\\n    SYNC: Denotes that the model endpoint type is sync.\\n    ASYNC: Denotes that the model endpoint type is async.\\n    STREAMING: Denotes that the model endpoint type is streaming.\\n    BATCH: Denotes that the model endpoint type is batch.'}], 'default': 'ASYNC'}, 'high_priority': {'type': 'boolean', 'title': 'High Priority', 'default': False}}, 'type': 'object', 'title': 'CreateModelEndpointConfig'}, 'fine_tuning_job_bundle_config': {'properties': {'registry': {'type': 'string', 'title': 'Registry'}, 'image': {'type': 'string', 'title': 'Image'}, 'tag': {'type': 'string', 'title': 'Tag'}, 'command': {'items': {'type': 'string'}, 'type': 'array', 'title': 'Command'}, 'env': {'additionalProperties': {'type': 'string'}, 'type': 'object', 'title': 'Env'}, 'mount_location': {'type': 'string', 'title': 'Mount Location', 'description': \"The filesystem location where the fine tuning job's configuration will be available when it is started.\", 'default': '/workspace/launch_specific/config.json'}, 'training_dataset_schema_type': {'allOf': [{'type': 'string', 'enum': ['GENERATION', 'RERANKING_QUESTIONS'], 'title': 'TrainingDatasetORMSchemaTypeEnum', 'description': 'An enumeration.'}], 'description': 'Optionally set required training and validation dataset schema'}, 'resources': {'properties': {'cpus': {'type': 'integer', 'title': 'Cpus', 'default': 3}, 'memory': {'type': 'string', 'title': 'Memory', 'default': '8Gi'}, 'storage': {'type': 'string', 'title': 'Storage', 'default': '16Gi'}, 'gpus': {'type': 'integer', 'title': 'Gpus', 'default': 0}, 'gpu_type': {'type': 'string', 'enum': ['nvidia-tesla-t4', 'nvidia-ampere-a10', 'nvidia-ampere-a100', 'nvidia-ampere-a100e', 'nvidia-hopper-h100', 'nvidia-hopper-h100-1g20gb', 'nvidia-hopper-h100-3g40gb'], 'title': 'GPUType', 'description': 'An enumeration.'}}, 'type': 'object', 'title': 'RequiredResources'}}, 'type': 'object', 'required': ['registry', 'image', 'tag'], 'title': 'FineTuningBundleConfiguration'}}, 'type': 'object', 'required': ['bundle_config'], 'title': 'LaunchVendorConfiguration', 'description': 'Configuration for launching a model using the Launch service which is an internal and\\nself-hosted service developed by Scale that deploys models on Kubernetes.\\n\\nAttributes:\\n    vendor: The vendor of the model template\\n    bundle_config: The bundle configuration of the model template\\n    endpoint_config: The endpoint configuration of the model template'}, 'model_creation_parameters_schema': {'allOf': [{'properties': {'parameters': {'items': {'properties': {'name': {'type': 'string', 'title': 'Name'}, 'type': {'anyOf': [{'type': 'string', 'enum': ['str']}, {'type': 'string', 'enum': ['int']}, {'type': 'string', 'enum': ['float']}, {'type': 'string', 'enum': ['bool']}], 'title': 'Type'}, 'description': {'type': 'string', 'title': 'Description'}, 'required': {'type': 'boolean', 'title': 'Required'}}, 'type': 'object', 'required': ['name', 'type', 'description', 'required'], 'title': 'ParameterSchemaField'}, 'type': 'array', 'title': 'Parameters'}}, 'type': 'object', 'required': ['parameters'], 'title': 'ParameterSchema'}], 'title': 'Model Creation Parameters Schema', 'description': 'The field names and types of available parameter fields which may be specified during model creation'}, 'model_request_parameters_schema': {'allOf': [{'properties': {'parameters': {'items': {'properties': {'name': {'type': 'string', 'title': 'Name'}, 'type': {'anyOf': [{'type': 'string', 'enum': ['str']}, {'type': 'string', 'enum': ['int']}, {'type': 'string', 'enum': ['float']}, {'type': 'string', 'enum': ['bool']}], 'title': 'Type'}, 'description': {'type': 'string', 'title': 'Description'}, 'required': {'type': 'boolean', 'title': 'Required'}}, 'type': 'object', 'required': ['name', 'type', 'description', 'required'], 'title': 'ParameterSchemaField'}, 'type': 'array', 'title': 'Parameters'}}, 'type': 'object', 'required': ['parameters'], 'title': 'ParameterSchema'}], 'title': 'Model Request Parameters Schema', 'description': \"The field names and types of available parameter fields which may be specified in a model execution API's `model_request_parameters` field.\"}, 'account_id': {'type': 'string', 'title': 'Account Id', 'description': 'The ID of the account that owns the given entity.', 'can_patch': False}}, 'type': 'object', 'required': ['name', 'endpoint_type', 'model_type', 'vendor_configuration', 'account_id'], 'title': 'ModelTemplateRequest'}\n",
      "{'properties': {'base_model_id': {'type': 'string', 'title': 'Base Model Id'}, 'vendor_configuration': {'oneOf': [{'properties': {'vendor': {'type': 'string', 'enum': ['LAUNCH'], 'title': 'Vendor', 'default': 'LAUNCH'}, 'hyperparameters': {'type': 'object', 'title': 'Hyperparameters'}, 'wandb_config': {'type': 'object', 'title': 'Wandb Config'}, 'suffix': {'type': 'string', 'title': 'Suffix'}, 'output': {'type': 'string', 'title': 'Output'}}, 'type': 'object', 'title': 'LaunchFineTuningJobConfiguration'}, {'properties': {'vendor': {'type': 'string', 'enum': ['LLMENGINE'], 'title': 'Vendor', 'default': 'LLMENGINE'}, 'hyperparameters': {'type': 'object', 'title': 'Hyperparameters'}, 'wandb_config': {'type': 'object', 'title': 'Wandb Config'}, 'suffix': {'type': 'string', 'title': 'Suffix'}, 'output': {'type': 'string', 'title': 'Output'}}, 'type': 'object', 'title': 'LLMEngineFineTuningJobConfiguration'}, {'properties': {'vendor': {'type': 'string', 'enum': ['OPENAI'], 'title': 'Vendor', 'default': 'OPENAI'}, 'hyperparameters': {'type': 'object', 'title': 'Hyperparameters'}, 'suffix': {'type': 'string', 'title': 'Suffix'}}, 'type': 'object', 'title': 'OpenAIFineTuningJobConfiguration'}], 'title': 'FineTuningJobVendorConfiguration', 'discriminator': {'propertyName': 'vendor', 'mapping': {'LAUNCH': '#/components/schemas/LaunchFineTuningJobConfiguration', 'LLMENGINE': '#/components/schemas/LLMEngineFineTuningJobConfiguration', 'OPENAI': '#/components/schemas/OpenAIFineTuningJobConfiguration'}}}, 'fine_tuned_model_id': {'type': 'string', 'title': 'Fine Tuned Model Id'}, 'training_dataset_id': {'type': 'string', 'title': 'Training Dataset Id'}, 'validation_dataset_id': {'type': 'string', 'title': 'Validation Dataset Id'}, 'account_id': {'type': 'string', 'title': 'Account Id', 'description': 'The ID of the account that owns the given entity.', 'can_patch': False}}, 'type': 'object', 'required': ['training_dataset_id', 'account_id'], 'title': 'FineTuningJobRequest'}\n",
      "{'properties': {'account_id': {'type': 'string', 'title': 'Account Id', 'description': 'The ID of the account that owns the given entity.'}, 'name': {'type': 'string', 'title': 'Name', 'description': 'The name of the dataset'}, 'schema_type': {'allOf': [{'type': 'string', 'enum': ['GENERATION', 'RERANKING_QUESTIONS'], 'title': 'TrainingDatasetORMSchemaTypeEnum', 'description': 'An enumeration.'}], 'description': 'The schema type of the dataset, currently only GENERATION is supported'}, 'file': {'type': 'string', 'format': 'binary', 'title': 'File', 'description': 'The file to upload as the training dataset'}}, 'type': 'object', 'required': ['account_id', 'name', 'schema_type', 'file'], 'title': 'Body_POST-V4-/training-datasets'}\n",
      "{'properties': {'name': {'type': 'string', 'title': 'Name'}, 'description': {'type': 'string', 'title': 'Description', 'description': 'Optional description of the application variant'}, 'configuration': {'properties': {'nodes': {'items': {'properties': {'id': {'type': 'string', 'title': 'Id'}, 'application_node_schema_id': {'type': 'string', 'enum': ['text_input_schema', 'text_output_schema', 'knowledge_base_schema', 'reranker_schema', 'prompt_engineering_schema', 'completion_model_schema', 'external_endpoint_schema'], 'title': 'NodeSchemaId', 'description': 'An enumeration.'}, 'configuration': {'additionalProperties': {'properties': {'value': {'title': 'Value'}}, 'type': 'object', 'required': ['value'], 'title': 'ConfigurationFieldValue'}, 'type': 'object', 'title': 'Configuration', 'default': {}}}, 'type': 'object', 'required': ['id', 'application_node_schema_id'], 'title': 'ApplicationNode'}, 'type': 'array', 'title': 'Nodes'}, 'edges': {'items': {'properties': {'from_node': {'type': 'string', 'title': 'From Node'}, 'to_node': {'type': 'string', 'title': 'To Node'}, 'from_field': {'type': 'string', 'title': 'From Field'}, 'to_field': {'type': 'string', 'title': 'To Field'}}, 'type': 'object', 'required': ['from_node', 'to_node', 'from_field', 'to_field'], 'title': 'ApplicationEdge'}, 'type': 'array', 'title': 'Edges'}}, 'type': 'object', 'required': ['nodes', 'edges'], 'title': 'ApplicationConfiguration'}, 'version': {'type': 'string', 'enum': ['V0'], 'title': 'ApplicationSchemaVersion', 'description': \"An enum representing the version states of an application and its nodes' schemas.\\nAttributes:\\n    V0: The initial version of an application schema.\"}, 'application_spec_id': {'type': 'string', 'title': 'Application Spec Id'}, 'account_id': {'type': 'string', 'title': 'Account Id', 'description': 'The ID of the account that owns the given entity.', 'can_patch': False}}, 'type': 'object', 'required': ['name', 'configuration', 'version', 'application_spec_id', 'account_id'], 'title': 'ApplicationVariantRequest'}\n",
      "{'properties': {'name': {'type': 'string', 'title': 'Name'}, 'endpoint': {'type': 'string', 'title': 'Endpoint', 'can_patch': False}, 'application_variant_id': {'type': 'string', 'title': 'Application Variant Id', 'can_patch': False}, 'is_active': {'type': 'boolean', 'title': 'Is Active'}, 'account_id': {'type': 'string', 'title': 'Account Id', 'description': 'The ID of the account that owns the given entity.', 'can_patch': False}}, 'type': 'object', 'required': ['name', 'endpoint', 'application_variant_id', 'is_active', 'account_id'], 'title': 'ApplicationDeploymentRequest'}\n",
      "{'properties': {'application_variant_id': {'type': 'string', 'title': 'Application Variant Id', 'can_patch': False}, 'account_id': {'type': 'string', 'title': 'Account Id', 'description': 'The ID of the account that owns the given entity.', 'optional_in_request': True, 'can_patch': False}, 'evaluation_dataset_ids': {'items': {'type': 'string'}, 'type': 'array', 'minItems': 1, 'title': 'Evaluation Dataset Ids'}}, 'type': 'object', 'required': ['application_variant_id', 'evaluation_dataset_ids'], 'title': 'ApplicationVariantReportGenerationRequest'}\n",
      "{'properties': {'inputs': {'additionalProperties': {'type': 'object'}, 'type': 'object', 'title': 'Inputs', 'description': 'Input data for the application. You must provide inputs for each input node'}, 'history': {'items': {'properties': {'request': {'type': 'string', 'title': 'Request', 'description': 'Request inputs'}, 'response': {'type': 'string', 'title': 'Response', 'description': 'Response outputs'}}, 'type': 'object', 'required': ['request', 'response'], 'title': 'ApplicationRequestResponsePair'}, 'type': 'array', 'title': 'History', 'description': 'History of the application', 'default': []}, 'nodes': {'items': {'properties': {'id': {'type': 'string', 'title': 'Id'}, 'application_node_schema_id': {'type': 'string', 'enum': ['text_input_schema', 'text_output_schema', 'knowledge_base_schema', 'reranker_schema', 'prompt_engineering_schema', 'completion_model_schema', 'external_endpoint_schema'], 'title': 'NodeSchemaId', 'description': 'An enumeration.'}, 'configuration': {'additionalProperties': {'properties': {'value': {'title': 'Value'}}, 'type': 'object', 'required': ['value'], 'title': 'ConfigurationFieldValue'}, 'type': 'object', 'title': 'Configuration', 'default': {}}}, 'type': 'object', 'required': ['id', 'application_node_schema_id'], 'title': 'ApplicationNode'}, 'type': 'array', 'title': 'Nodes', 'description': 'List of nodes in the application graph'}, 'edges': {'items': {'properties': {'from_node': {'type': 'string', 'title': 'From Node'}, 'to_node': {'type': 'string', 'title': 'To Node'}, 'from_field': {'type': 'string', 'title': 'From Field'}, 'to_field': {'type': 'string', 'title': 'To Field'}}, 'type': 'object', 'required': ['from_node', 'to_node', 'from_field', 'to_field'], 'title': 'ApplicationEdge'}, 'type': 'array', 'title': 'Edges', 'description': 'List of edges in the application graph'}, 'version': {'allOf': [{'type': 'string', 'enum': ['V0'], 'title': 'ApplicationSchemaVersion', 'description': \"An enum representing the version states of an application and its nodes' schemas.\\nAttributes:\\n    V0: The initial version of an application schema.\"}], 'description': 'Version of the application schema'}}, 'type': 'object', 'required': ['inputs', 'nodes', 'edges', 'version'], 'title': 'TestApplicationProcessingRequest'}\n",
      "{'properties': {'inputs': {'additionalProperties': {'type': 'object'}, 'type': 'object', 'title': 'Inputs', 'description': 'Input data for the application. You must provide inputs for each input node'}, 'history': {'items': {'properties': {'request': {'type': 'string', 'title': 'Request', 'description': 'Request inputs'}, 'response': {'type': 'string', 'title': 'Response', 'description': 'Response outputs'}}, 'type': 'object', 'required': ['request', 'response'], 'title': 'ApplicationRequestResponsePair'}, 'type': 'array', 'title': 'History', 'description': 'History of the application', 'default': []}}, 'type': 'object', 'required': ['inputs'], 'title': 'ApplicationProcessingRequest'}\n",
      "{'properties': {'inputs': {'additionalProperties': {'type': 'object'}, 'type': 'object', 'title': 'Inputs', 'description': 'Input data for the application. You must provide inputs for each input node'}, 'history': {'items': {'properties': {'request': {'type': 'string', 'title': 'Request', 'description': 'Request inputs'}, 'response': {'type': 'string', 'title': 'Response', 'description': 'Response outputs'}}, 'type': 'object', 'required': ['request', 'response'], 'title': 'ApplicationRequestResponsePair'}, 'type': 'array', 'title': 'History', 'description': 'History of the application', 'default': []}}, 'type': 'object', 'required': ['inputs'], 'title': 'ApplicationProcessingRequest'}\n",
      "{'properties': {'nodes': {'items': {'properties': {'id': {'type': 'string', 'title': 'Id'}, 'application_node_schema_id': {'type': 'string', 'enum': ['text_input_schema', 'text_output_schema', 'knowledge_base_schema', 'reranker_schema', 'prompt_engineering_schema', 'completion_model_schema', 'external_endpoint_schema'], 'title': 'NodeSchemaId', 'description': 'An enumeration.'}, 'configuration': {'additionalProperties': {'properties': {'value': {'title': 'Value'}}, 'type': 'object', 'required': ['value'], 'title': 'ConfigurationFieldValue'}, 'type': 'object', 'title': 'Configuration', 'default': {}}}, 'type': 'object', 'required': ['id', 'application_node_schema_id'], 'title': 'ApplicationNode'}, 'type': 'array', 'title': 'Nodes', 'description': 'List of nodes in the application graph'}, 'edges': {'items': {'properties': {'from_node': {'type': 'string', 'title': 'From Node'}, 'to_node': {'type': 'string', 'title': 'To Node'}, 'from_field': {'type': 'string', 'title': 'From Field'}, 'to_field': {'type': 'string', 'title': 'To Field'}}, 'type': 'object', 'required': ['from_node', 'to_node', 'from_field', 'to_field'], 'title': 'ApplicationEdge'}, 'type': 'array', 'title': 'Edges', 'description': 'List of edges in the application graph'}, 'version': {'allOf': [{'type': 'string', 'enum': ['V0'], 'title': 'ApplicationSchemaVersion', 'description': \"An enum representing the version states of an application and its nodes' schemas.\\nAttributes:\\n    V0: The initial version of an application schema.\"}], 'description': 'Version of the application schema'}}, 'type': 'object', 'required': ['nodes', 'edges', 'version'], 'title': 'ApplicationValidationRequest'}\n",
      "{'properties': {'title': {'type': 'string', 'title': 'Title'}, 'application_variant_id': {'type': 'string', 'title': 'Application Variant Id', 'can_patch': False}, 'account_id': {'type': 'string', 'title': 'Account Id', 'description': 'The ID of the account that owns the given entity.', 'can_patch': False}}, 'type': 'object', 'required': ['title', 'application_variant_id', 'account_id'], 'title': 'ChatThreadRequest'}\n",
      "{'properties': {'title': {'type': 'string', 'title': 'Title'}, 'theme_vars': {'properties': {'accentPrimary': {'type': 'string', 'title': 'Accentprimary'}, 'accentSecondary': {'type': 'string', 'title': 'Accentsecondary'}, 'background': {'type': 'string', 'title': 'Background'}, 'foreground': {'type': 'string', 'title': 'Foreground'}}, 'type': 'object', 'title': 'ThemeVars'}, 'logo_blob': {'type': 'string', 'title': 'Logo Blob'}, 'account_id': {'type': 'string', 'title': 'Account Id', 'description': 'The ID of the account that owns the given entity.', 'can_patch': False}}, 'type': 'object', 'required': ['title', 'theme_vars', 'logo_blob', 'account_id'], 'title': 'ThemeRequest'}\n",
      "removing... query\n",
      "removing... delete\n",
      "removing... cancel\n",
      "removing... verify\n",
      "removing... rank\n",
      "removing... synthesis\n",
      "removing... execute\n",
      "removing... embedding\n",
      "removing... reranking\n",
      "removing... claim-task\n",
      "removing... batch\n",
      "removing... approve\n",
      "removing... publish\n",
      "removing... approve-batch\n",
      "removing... proces\n",
      "removing... validate\n",
      "[GraphNode(asset_name='knowledge-base', dependent_assets=[], inputs=['knowledge_base_name', 'account_id', 'metadata', 'embedding_config'], route='/v4/knowledge-bases', method='post', tag='Knowledge Bases'), GraphNode(asset_name='upload', dependent_assets=['knowledge-base'], inputs=['knowledge_base_id'], route='/v4/knowledge-bases/{knowledge_base_id}/uploads', method='post', tag='Knowledge Bases'), GraphNode(asset_name='completion', dependent_assets=['model-deployment'], inputs=['prompt', 'model_deployment_id', 'temperature', 'presence_penalty', 'top_k', 'top_p', 'model_request_parameters', 'frequency_penalty', 'max_tokens', 'stop_sequences'], route='/v4/models/{model_deployment_id}/completions', method='post', tag='Models'), GraphNode(asset_name='chat-completion', dependent_assets=['model-deployment'], inputs=['prompt', 'model_deployment_id', 'temperature', 'presence_penalty', 'top_k', 'top_p', 'model_request_parameters', 'frequency_penalty', 'max_tokens', 'stop_sequences', 'chat_history'], route='/v4/models/{model_deployment_id}/chat-completions', method='post', tag='Models'), GraphNode(asset_name='deployment', dependent_assets=['model-instance'], inputs=['deployment_metadata', 'account_id', 'name', 'model_instance_id', 'model_creation_parameters', 'vendor_configuration'], route='/v4/models/{model_instance_id}/deployments', method='post', tag='Models'), GraphNode(asset_name='account', dependent_assets=[], inputs=['account_name'], route='/accounts', method='post', tag='Accounts'), GraphNode(asset_name='evaluation-config', dependent_assets=['studio-project', 'question-set'], inputs=['evaluation_type', 'question_set_id', 'studio_project_id', 'account_id', 'x-selected-account-id'], route='/v4/evaluation-configs', method='post', tag='Evaluation Configs'), GraphNode(asset_name='evaluation-dataset', dependent_assets=['knowledge-base'], inputs=['type', 'schema_type', 'account_id', 'name', 'x-selected-account-id', 'knowledge_base_id'], route='/v4/evaluation-datasets', method='post', tag='Evaluation Datasets'), GraphNode(asset_name='evaluation-dataset-version', dependent_assets=['evaluation-dataset'], inputs=['account_id', 'evaluation_dataset_id', 'x-selected-account-id'], route='/v4/evaluation-datasets/{evaluation_dataset_id}/evaluation-dataset-versions', method='post', tag='Evaluation Datasets'), GraphNode(asset_name='test-case', dependent_assets=['evaluation-dataset'], inputs=['test_case_metadata', 'schema_type', 'account_id', 'evaluation_dataset_id', 'x-selected-account-id', 'chat_history', 'test_case_data'], route='/v4/evaluation-datasets/{evaluation_dataset_id}/test-cases', method='post', tag='Evaluation Datasets'), GraphNode(asset_name='studio-project', dependent_assets=[], inputs=['studio_api_key', 'description', 'account_id', 'name', 'x-selected-account-id'], route='/v4/studio-projects', method='post', tag='Studio Projects'), GraphNode(asset_name='application-spec', dependent_assets=['theme'], inputs=['description', 'theme_id', 'account_id', 'name', 'x-selected-account-id', 'run_online_evaluation'], route='/v4/application-specs', method='post', tag='Application Specs'), GraphNode(asset_name='evaluation', dependent_assets=['application-variant', 'evaluation-dataset', 'application-spec', 'evaluation-config'], inputs=['type', 'application_spec_id', 'description', 'tags', 'evaluation_config', 'evaluation_config_id', 'name', 'account_id', 'x-selected-account-id', 'application_variant_id', 'evaluation_dataset_id', 'evaluation_dataset_version'], route='/v4/evaluations', method='post', tag='Evaluations'), GraphNode(asset_name='test-case-result', dependent_assets=['annotated-by-user', 'test-case', 'application-spec', 'evaluation'], inputs=['time_spent_labeling_s', 'annotated_by_user_id', 'test_case_id', 'audit_comment', 'application_spec_id', 'x-selected-account-id', 'audit_status', 'test_case_evaluation_data_schema', 'audit_required', 'account_id', 'test_case_evaluation_data', 'result', 'evaluation_dataset_version_num', 'evaluation_id'], route='/v4/evaluations/{evaluation_id}/test-case-results', method='post', tag='Evaluations'), GraphNode(asset_name='question', dependent_assets=[], inputs=['prompt', 'type', 'multi', 'dropdown', 'account_id', 'choices', 'required', 'conditions', 'title', 'x-selected-account-id'], route='/v4/questions', method='post', tag='Questions'), GraphNode(asset_name='question-set', dependent_assets=['question'], inputs=['account_id', 'name', 'question_ids', 'x-selected-account-id'], route='/v4/question-sets', method='post', tag='Question Sets'), GraphNode(asset_name='knowledge-base-datum-source', dependent_assets=[], inputs=['data_source_auth_config', 'description', 'name', 'account_id', 'x-selected-account-id', 'data_source_config'], route='/v4/knowledge-base-data-sources', method='post', tag='Knowledge Base Data Sources'), GraphNode(asset_name='upload-schedule', dependent_assets=['knowledge-base-datum-source', 'knowledge-base'], inputs=['interval', 'chunking_strategy_config', 'next_run_at', 'account_id', 'x-selected-account-id', 'knowledge_base_id', 'knowledge_base_data_source_id'], route='/v4/knowledge-bases/{knowledge_base_id}/upload-schedules', method='post', tag='Knowledge Bases'), GraphNode(asset_name='autogenerated-draft-test-case', dependent_assets=['evaluation-dataset'], inputs=['schema_type', 'approved', 'account_id', 'x-selected-account-id', 'topic_str', 'evaluation_dataset_id', 'test_case_data'], route='/v4/evaluation-datasets/{evaluation_dataset_id}/autogenerated-draft-test-cases', method='post', tag='Evaluation Datasets'), GraphNode(asset_name='generation-job', dependent_assets=['evaluation-dataset'], inputs=['evaluation_dataset_id', 'num_test_cases', 'x-selected-account-id'], route='/v4/evaluation-datasets/{evaluation_dataset_id}/generation-jobs', method='post', tag='Evaluation Datasets'), GraphNode(asset_name='model', dependent_assets=['model-group', 'base-model', 'model-template'], inputs=['base_model_metadata', 'description', 'model_vendor', 'model_template_id', 'name', 'base_model_id', 'account_id', 'model_card', 'x-selected-account-id', 'model_group_id', 'model_type', 'model_creation_parameters', 'training_data_card'], route='/v4/models', method='post', tag='Models'), GraphNode(asset_name='model-group', dependent_assets=[], inputs=['account_id', 'name', 'description', 'x-selected-account-id'], route='/v4/model-groups', method='post', tag='Models'), GraphNode(asset_name='model-template', dependent_assets=[], inputs=['model_request_parameters_schema', 'name', 'account_id', 'endpoint_type', 'x-selected-account-id', 'model_creation_parameters_schema', 'model_type', 'vendor_configuration'], route='/v4/model-templates', method='post', tag='Model Templates V3 (Beta)'), GraphNode(asset_name='fine-tuning-job', dependent_assets=['fine-tuned-model', 'validation-dataset', 'base-model', 'training-dataset'], inputs=['fine_tuned_model_id', 'training_dataset_id', 'base_model_id', 'account_id', 'validation_dataset_id', 'x-selected-account-id', 'vendor_configuration'], route='/v4/fine-tuning-jobs', method='post', tag='Fine Tuning Jobs V3 (Beta)'), GraphNode(asset_name='training-dataset', dependent_assets=[], inputs=['account_id', 'schema_type', 'file', 'name'], route='/v4/training-datasets', method='post', tag='Training Datasets V3 (Beta)'), GraphNode(asset_name='application-variant', dependent_assets=['application-spec'], inputs=['application_spec_id', 'description', 'name', 'account_id', 'x-selected-account-id', 'version', 'configuration'], route='/v4/application-variants', method='post', tag='Applications'), GraphNode(asset_name='application-deployment', dependent_assets=['application-variant'], inputs=['x-selected-account-id', 'name', 'account_id', 'endpoint', 'application_variant_id', 'is_active'], route='/v4/application-deployments', method='post', tag='Applications'), GraphNode(asset_name='application-variant-report', dependent_assets=['application-variant', 'evaluation-dataset'], inputs=['application_variant_id', 'account_id', 'evaluation_dataset_ids', 'x-selected-account-id'], route='/v4/application-variant-reports', method='post', tag='Applications'), GraphNode(asset_name='thread', dependent_assets=['application-variant'], inputs=['application_variant_id', 'account_id', 'title'], route='/v4/applications/{application_variant_id}/threads', method='post', tag='Applications'), GraphNode(asset_name='theme', dependent_assets=[], inputs=['account_id', 'logo_blob', 'title', 'x-selected-account-id', 'theme_vars'], route='/v4/themes', method='post', tag='Chat Themes')]\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "source": [
    "# Dictionary to store anytree nodes\n",
    "from anytree import Node, RenderTree\n",
    "\n",
    "# Dictionary to store anytree nodes\n",
    "nodes_dict = defaultdict(lambda: None)\n",
    "sink_nodes = [node for node in graph.nodes() if graph.out_degree(node) == 0]\n",
    "\n",
    "# Function to build the tree using anytree\n",
    "def build_tree_for_node(_graph, _node):\n",
    "    # Initialize the root node for the tree\n",
    "    _root = Node(_node)\n",
    "    nodes_dict[_node] = _root\n",
    "    # Use a stack for DFS\n",
    "    stack = [_node]\n",
    "    visited = set()\n",
    "\n",
    "    while stack:\n",
    "        node = stack.pop()\n",
    "        if node not in visited:\n",
    "            visited.add(node)\n",
    "            for pred in _graph.predecessors(node):\n",
    "                if pred not in nodes_dict:\n",
    "                    nodes_dict[pred] = Node(pred, parent=nodes_dict[node])\n",
    "                else:\n",
    "                    nodes_dict[pred].parent = nodes_dict[node]\n",
    "                stack.append(pred)\n",
    "    return _root\n",
    "\n",
    "\n",
    "def print_tree(_root: Node):\n",
    "    print(f\"Tree for {sink_node}:\")\n",
    "    for pre, _, node in RenderTree(_root):\n",
    "        print(\"%s%s\" % (pre, node.name))\n",
    "\n",
    "# Visualize trees for each sink node\n",
    "for sink_node in sink_nodes:\n",
    "    root = build_tree_for_node(graph, sink_node)\n",
    "    print_tree(root)\n",
    "    print(\"\\n\" + \"=\"*40)  # Separator between trees"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T05:02:03.332483Z",
     "start_time": "2024-07-09T05:02:03.328748Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree for upload:\n",
      "upload\n",
      " knowledge-base\n",
      "\n",
      "========================================\n",
      "Tree for completion:\n",
      "completion\n",
      " model-deployment\n",
      "\n",
      "========================================\n",
      "Tree for chat-completion:\n",
      "chat-completion\n",
      " model-deployment\n",
      "\n",
      "========================================\n",
      "Tree for deployment:\n",
      "deployment\n",
      " model-instance\n",
      "\n",
      "========================================\n",
      "Tree for account:\n",
      "account\n",
      "\n",
      "========================================\n",
      "Tree for evaluation-dataset-version:\n",
      "evaluation-dataset-version\n",
      " evaluation-dataset\n",
      "     knowledge-base\n",
      "\n",
      "========================================\n",
      "Tree for test-case-result:\n",
      "test-case-result\n",
      " annotated-by-user\n",
      " test-case\n",
      "    evaluation-dataset\n",
      "        knowledge-base\n",
      " evaluation\n",
      "     application-variant\n",
      "        application-spec\n",
      "            theme\n",
      "     evaluation-config\n",
      "         studio-project\n",
      "         question-set\n",
      "             question\n",
      "\n",
      "========================================\n",
      "Tree for upload-schedule:\n",
      "upload-schedule\n",
      " knowledge-base-datum-source\n",
      " knowledge-base\n",
      "\n",
      "========================================\n",
      "Tree for autogenerated-draft-test-case:\n",
      "autogenerated-draft-test-case\n",
      " evaluation-dataset\n",
      "     knowledge-base\n",
      "\n",
      "========================================\n",
      "Tree for generation-job:\n",
      "generation-job\n",
      " evaluation-dataset\n",
      "     knowledge-base\n",
      "\n",
      "========================================\n",
      "Tree for model:\n",
      "model\n",
      " model-group\n",
      " base-model\n",
      " model-template\n",
      "\n",
      "========================================\n",
      "Tree for fine-tuning-job:\n",
      "fine-tuning-job\n",
      " fine-tuned-model\n",
      " validation-dataset\n",
      " base-model\n",
      " training-dataset\n",
      "\n",
      "========================================\n",
      "Tree for application-deployment:\n",
      "application-deployment\n",
      " application-variant\n",
      "     application-spec\n",
      "         theme\n",
      "\n",
      "========================================\n",
      "Tree for application-variant-report:\n",
      "application-variant-report\n",
      " application-variant\n",
      "    application-spec\n",
      "        theme\n",
      " evaluation-dataset\n",
      "     knowledge-base\n",
      "\n",
      "========================================\n",
      "Tree for thread:\n",
      "thread\n",
      " application-variant\n",
      "     application-spec\n",
      "         theme\n",
      "\n",
      "========================================\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "source": [
    "node_assets = [str(node) for node in graph.nodes()]\n",
    "node_assets"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T05:02:03.336566Z",
     "start_time": "2024-07-09T05:02:03.334218Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['knowledge-base',\n",
       " 'upload',\n",
       " 'completion',\n",
       " 'chat-completion',\n",
       " 'deployment',\n",
       " 'account',\n",
       " 'evaluation-config',\n",
       " 'evaluation-dataset',\n",
       " 'evaluation-dataset-version',\n",
       " 'test-case',\n",
       " 'studio-project',\n",
       " 'application-spec',\n",
       " 'evaluation',\n",
       " 'test-case-result',\n",
       " 'question',\n",
       " 'question-set',\n",
       " 'knowledge-base-datum-source',\n",
       " 'upload-schedule',\n",
       " 'autogenerated-draft-test-case',\n",
       " 'generation-job',\n",
       " 'model',\n",
       " 'model-group',\n",
       " 'model-template',\n",
       " 'fine-tuning-job',\n",
       " 'training-dataset',\n",
       " 'application-variant',\n",
       " 'application-deployment',\n",
       " 'application-variant-report',\n",
       " 'thread',\n",
       " 'theme',\n",
       " 'model-deployment',\n",
       " 'model-instance',\n",
       " 'annotated-by-user',\n",
       " 'base-model',\n",
       " 'fine-tuned-model',\n",
       " 'validation-dataset']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "source": [
    "asset_tree = build_tree_for_node(graph, \"test-case\")\n",
    "\n",
    "print(print_tree(asset_tree))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T05:02:03.339045Z",
     "start_time": "2024-07-09T05:02:03.337339Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree for thread:\n",
      "test-case\n",
      " evaluation-dataset\n",
      "     knowledge-base\n",
      "None\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T05:02:03.347670Z",
     "start_time": "2024-07-09T05:02:03.339553Z"
    }
   },
   "cell_type": "code",
   "source": "assert False",
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[52], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "\u001B[0;31mAssertionError\u001B[0m: "
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "hello_world = 'hello world (placeholder)'",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()\n",
    "ASST_ID = os.environ[\"OPENAI_PARROT_AGENT_ASST\"]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from typing import List\n",
    "# tools for assistant\n",
    "import httpx\n",
    "\n",
    "BASE_URL = \"https://example.com/api\"\n",
    "HEADERS = {\"Authorization\": \"Bearer your_token_here\"}\n",
    "\n",
    "def run_api_call(route: str, method: str, data: dict = None) -> dict:\n",
    "    \"\"\"\n",
    "    Function to make an API call to a specified route using the specified method.\n",
    "    Supports GET and POST methods, with data only being used for POST.\n",
    "\n",
    "    Parameters:\n",
    "        route (str): The API route.\n",
    "        method (str): The HTTP method ('GET' or 'POST').\n",
    "        data (dict, optional): Data to send with POST requests.\n",
    "\n",
    "    Returns:\n",
    "        dict: The response from the API as a dictionary.\n",
    "    \"\"\"\n",
    "    url = f\"{BASE_URL}/{route.strip('/')}\"  # Ensure the route is correctly appended to the base URL\n",
    "    with httpx.Client(headers=HEADERS) as client:\n",
    "        if method.upper() == 'POST':\n",
    "            response = client.post(url, json=data)\n",
    "        elif method.upper() == 'GET':\n",
    "            response = client.get(url)\n",
    "        else:\n",
    "            return {\"error\": f\"Unsupported method: {method}\"}\n",
    "\n",
    "        # Return the JSON response if possible, otherwise return the status code\n",
    "        return response.json() if response.is_success else {'status_code': response.status_code, 'detail': response.text}\n",
    "\n",
    "def get_dependency_tree(asset_names: List[str]):\n",
    "    # generate dependency tree\n",
    "    pass\n",
    "\n",
    "def get_routes_for_asset():\n",
    "    pass\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
